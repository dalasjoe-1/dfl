{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GetLotto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6XNJsEa8l3pZqQAMuob8j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dalasjoe-1/dfl/blob/master/GetLotto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6kMeQ2_aCfm"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from os import path\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "main_url = \"https://www.dhlottery.co.kr/gameResult.do?method=byWin\" # 마지막 회차를 얻기 위한 주소\n",
        "basic_url = \"https://www.dhlottery.co.kr/gameResult.do?method=byWin&drwNo=\" # 임의의 회차를 얻기 위한 주소\n",
        "\n",
        "# 마지막 회차 정보를 가져옴\n",
        "def GetLast(): \n",
        "    resp = requests.get(main_url)\n",
        "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
        "    result = str(soup.find(\"meta\", {\"id\" : \"desc\", \"name\" : \"description\"})['content'])\n",
        "    s_idx = result.find(\" \")\n",
        "    e_idx = result.find(\"회\")\n",
        "    return int(result[s_idx + 1 : e_idx])\n",
        "\n",
        "    # 지정된 파일에 지정된 범위의 회차 정보를 기록함\n",
        "def Crawler(s_count, e_count, fp):\n",
        "    for i in range(s_count , e_count + 1):\n",
        "        crawler_url = basic_url + str(i)\n",
        "        resp = requests.get(crawler_url)\n",
        "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "        text = soup.text\n",
        "\n",
        "        s_idx = text.find(\" 당첨결과\")\n",
        "        s_idx = text.find(\"당첨번호\", s_idx) + 4\n",
        "        e_idx = text.find(\"보너스\", s_idx)\n",
        "        numbers = text[s_idx:e_idx].strip().split()\n",
        "\n",
        "        s_idx = e_idx + 3\n",
        "        e_idx = s_idx + 3\n",
        "        bonus = text[s_idx:e_idx].strip()\n",
        "\n",
        "        s_idx = text.find(\"1등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money1 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"2등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money2 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"3등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money3 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"4등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money4 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"5등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money5 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        line = str(i) + ',' + numbers[0] + ',' + numbers[1] + ',' + numbers[2] + ',' + numbers[3] + ',' + numbers[4] + ',' + numbers[5] + ',' + bonus + ',' + money1 + ',' + money2 + ',' + money3 + ',' + money4 + ',' + money5\n",
        "        print(line)\n",
        "        line += '\\n'\n",
        "        f.write(line)\n",
        "\n",
        "last = GetLast() # 마지막 회차를 가져옴\n",
        "\n",
        "otto_dir_name='lotto'\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "lotto_base_dir=path.join('./gdrive/My Drive/', '')\n",
        "if not path.exists(lotto_base_dir):\n",
        "  print('Check your google drive directory. See you file explorer')\n",
        "\n",
        "with open(path.join(lotto_base_dir, \"lotto_data.txt\"), \"w\") as f:\n",
        "    Crawler(1, last, f) # 처음부터 마지막 회차까지 저장\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_onUt3XBNvV"
      },
      "source": [
        "fp = open('loto_data.csv', 'w')\n",
        "fp.write(\"1111\\n\")\n",
        "fp.write(\"2222\\n\")\n",
        "fp.close()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptgXE1snCCFo",
        "outputId": "1443af86-fa20-425e-d88a-07cdfc604e99"
      },
      "source": [
        "from os import path\n",
        "from google.colab import drive\n",
        "\n",
        "lotto_dir_name='lotto'\n",
        "drive.mount('/content/gdrive')\n",
        "lotto_base_dir=path.join('./gdrive/My Drive/', '')\n",
        "if not path.exists(lotto_base_dir):\n",
        "  print('Check your google drive directory. See you file explorer')\n",
        "\n",
        "with open(path.join(lotto_base_dir, \"myfile.txt\"), \"w\") as f:\n",
        "    f.write(\"Google Colab is good!!!\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWNFeVuR0KhD",
        "outputId": "f7e114e2-d576-42d3-a0ff-d091864b2db2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 당첨번호를 원핫인코딩벡터(ohbin)으로 변환\n",
        "def numbers2ohbin(numbers):\n",
        "\n",
        "    ohbin = np.zeros(45) #45개의 빈 칸을 만듬\n",
        "\n",
        "    for i in range(6): #여섯개의 당첨번호에 대해서 반복함\n",
        "        ohbin[int(numbers[i])-1] = 1 #로또번호가 1부터 시작하지만 벡터의 인덱스 시작은 0부터 시작하므로 1을 뺌\n",
        "    \n",
        "    return ohbin\n",
        "\n",
        "# 원핫인코딩벡터(ohbin)를 번호로 변환\n",
        "def ohbin2numbers(ohbin):\n",
        "\n",
        "    numbers = []\n",
        "    \n",
        "    for i in range(len(ohbin)):\n",
        "        if ohbin[i] == 1.0: # 1.0으로 설정되어 있으면 해당 번호를 반환값에 추가한다.\n",
        "            numbers.append(i+1)\n",
        "    \n",
        "    return numbers\n",
        "\n",
        "print(\"1:\" + str(numbers2ohbin([10,23,29,33,37,40])))\n",
        "print(\"2:\" + str(numbers2ohbin([9,13,21,25,32,42])))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1:[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "2:[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYHi1PhP0kNr",
        "outputId": "72ff9473-68ba-4b0e-f587-631ba5615b11"
      },
      "source": [
        "import numpy as np\n",
        "from os import path\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "rows = np.loadtxt(\"./drive/MyDrive/lotto_data.txt\", delimiter=\",\")\n",
        "row_count = len(rows)\n",
        "\n",
        "print(\"row count: \" + str(row_count))\n",
        "\n",
        "numbers = rows[:, 1:7]\n",
        "ohbins = list(map(numbers2ohbin, numbers))\n",
        "\n",
        "x_samples = ohbins[0:row_count-1]\n",
        "y_samples = ohbins[1:row_count]\n",
        "\n",
        "#원핫인코딩으로 표시\n",
        "print(\"ohbins\")\n",
        "print(\"X[0]: \" + str(x_samples[0]))\n",
        "print(\"Y[0]: \" + str(y_samples[0]))\n",
        "\n",
        "#번호로 표시\n",
        "print(\"numbers\")\n",
        "print(\"X[0]: \" + str(ohbin2numbers(x_samples[0])))\n",
        "print(\"Y[0]: \" + str(ohbin2numbers(y_samples[0])))\n",
        "\n",
        "train_idx = (0, 700)\n",
        "val_idx = (700, 800)\n",
        "test_idx = (800, len(x_samples))\n",
        "\n",
        "print(\"train: {0}, val: {1}, test: {2}\".format(train_idx, val_idx, test_idx))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "row count: 956\n",
            "ohbins\n",
            "X[0]: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "Y[0]: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "numbers\n",
            "X[0]: [10, 23, 29, 33, 37, 40]\n",
            "Y[0]: [9, 13, 21, 25, 32, 42]\n",
            "train: (0, 700), val: (700, 800), test: (800, 955)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUmYtLqC2L-n",
        "outputId": "c05d887a-8eb0-44b5-882e-3fa7a846c670"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "!pip install tensorflow-gpu==2.0.0-rc1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/2c/316e5aaa3fa76a43ed659a45aa2d79ea23308770fb6e5ff28e70ce6d67f9/tensorflow_gpu-2.0.0rc1-cp37-cp37m-manylinux2010_x86_64.whl (380.5MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.3.0)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 39.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.12.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.32.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 40.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.36.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.4.1)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, keras-applications, tensorflow-gpu\n",
            "Successfully installed keras-applications-1.0.8 tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-vuJrQn2pNt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "# 모델을 정의합니다.\n",
        "model = keras.Sequential([\n",
        "    keras.layers.LSTM(128, batch_input_shape=(1, 1, 45), return_sequences=False, stateful=True),\n",
        "    keras.layers.Dense(45, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 모델을 컴파일합니다.\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "qiZWGheL3DRZ",
        "outputId": "54a70bdc-7efc-463d-8e6c-7678c5ea3bfd"
      },
      "source": [
        "# 매 에포크마다 훈련과 검증의 손실 및 정확도를 기록하기 위한 변수\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "# 최대 100번 에포크까지 수행\n",
        "for epoch in range(100):\n",
        "\n",
        "    model.reset_states() # 중요! 매 에포크마다 1회부터 다시 훈련하므로 상태 초기화 필요\n",
        "\n",
        "    batch_train_loss = []\n",
        "    batch_train_acc = []\n",
        "    \n",
        "    for i in range(train_idx[0], train_idx[1]):\n",
        "        \n",
        "        xs = x_samples[i].reshape(1, 1, 45)\n",
        "        ys = y_samples[i].reshape(1, 45)\n",
        "        \n",
        "        loss, acc = model.train_on_batch(xs, ys) #배치만큼 모델에 학습시킴\n",
        "\n",
        "        batch_train_loss.append(loss)\n",
        "        batch_train_acc.append(acc)\n",
        "\n",
        "    train_loss.append(np.mean(batch_train_loss))\n",
        "    train_acc.append(np.mean(batch_train_acc))\n",
        "\n",
        "    batch_val_loss = []\n",
        "    batch_val_acc = []\n",
        "\n",
        "    for i in range(val_idx[0], val_idx[1]):\n",
        "\n",
        "        xs = x_samples[i].reshape(1, 1, 45)\n",
        "        ys = y_samples[i].reshape(1, 45)\n",
        "        \n",
        "        loss, acc = model.test_on_batch(xs, ys) #배치만큼 모델에 입력하여 나온 답을 정답과 비교함\n",
        "        \n",
        "        batch_val_loss.append(loss)\n",
        "        batch_val_acc.append(acc)\n",
        "\n",
        "    val_loss.append(np.mean(batch_val_loss))\n",
        "    val_acc.append(np.mean(batch_val_acc))\n",
        "\n",
        "    print('epoch {0:4d} train acc {1:0.3f} loss {2:0.3f} val acc {3:0.3f} loss {4:0.3f}'.format(epoch, np.mean(batch_train_acc), np.mean(batch_train_loss), np.mean(batch_val_acc), np.mean(batch_val_loss)))\n",
        "\n",
        "    model.save('model_{0:04d}.h5'.format(epoch+1))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch   32 train acc 0.949 loss 0.149 val acc 0.812 loss 0.591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5c2c112663cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#배치만큼 모델에 학습시킴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mbatch_train_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n\u001b[1;32m    271\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         logging.warning('The list of trainable weights is empty. Make sure that'\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m       \u001b[0mapply_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m       return distribute_ctx.get_replica_context().merge_call(\n\u001b[1;32m    439\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_prepare\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0mapply_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_prepare_local\u001b[0;34m(self, var_device, var_dtype, apply_state)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mlocal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0mbeta_1_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beta_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mbeta_2_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beta_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m_run_op\u001b[0;34m(a, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_run_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    910\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_add_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m   \u001b[0;34m\"\"\"Dispatches to add for strings and add_v2 for all other types.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mfwd_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_compatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2019\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/compat/compat.py\u001b[0m in \u001b[0;36mforward_compatible\u001b[0;34m(year, month, day)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0msource\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mafter\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_get_forward_compatibility_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/compat/compat.py\u001b[0m in \u001b[0;36m_get_forward_compatibility_date\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_forward_compatibility_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FORWARD_COMPATIBILITY_HORIZON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m   \u001b[0mdelta_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_FORWARD_COMPATIBILITY_DELTA_DAYS_VAR_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdelta_days\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_FORWARD_COMPATIBILITY_HORIZON_OVERRIDDEN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_days\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36mgetenv\u001b[0;34m(key, default)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0moptional\u001b[0m \u001b[0msecond\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mspecify\u001b[0m \u001b[0man\u001b[0m \u001b[0malternate\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     key, default and the result are str.\"\"\"\n\u001b[0;32m--> 776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0msupports_bytes_environ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'nt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "236sfZEu4dl6",
        "outputId": "e6123b4e-aba5-4f42-e81e-bdd895022ce1"
      },
      "source": [
        "# 88회부터 지금까지 1등부터 5등까지 상금의 평균낸다.\n",
        "mean_prize = [  np.mean(rows[87:, 8]),\n",
        "                np.mean(rows[87:, 9]),\n",
        "                np.mean(rows[87:, 10]),\n",
        "                np.mean(rows[87:, 11]),\n",
        "                np.mean(rows[87:, 12])]\n",
        "\n",
        "print(mean_prize)   "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2433380883.683544, 57117836.4890679, 1450540.3199079402, 52843.472957422324, 5000.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6f8o0HX4jMj"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWbNJbgk4uQx",
        "outputId": "f16e99ea-4089-4eb3-d664-167e551d49c7"
      },
      "source": [
        "# 등수와 상금을 반환함\n",
        "# 순위에 오르지 못한 경우에는 등수가 0으로 반환함\n",
        "def calc_reward(true_numbers, true_bonus, pred_numbers):\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for ps in pred_numbers:\n",
        "        if ps in true_numbers:\n",
        "            count += 1\n",
        "\n",
        "    if count == 6:\n",
        "        return 0, mean_prize[0]\n",
        "    elif count == 5 and true_bonus in pred_numbers:\n",
        "        return 1, mean_prize[1]\n",
        "    elif count == 5:\n",
        "        return 2, mean_prize[2]\n",
        "    elif count == 4:\n",
        "        return 3, mean_prize[3]\n",
        "    elif count == 3:\n",
        "        return 4, mean_prize[4]\n",
        "\n",
        "    return 5, 0\n",
        "\n",
        "def gen_numbers_from_probability(nums_prob):\n",
        "\n",
        "    ball_box = []\n",
        "\n",
        "    for n in range(45):\n",
        "        ball_count = int(nums_prob[n] * 100 + 1)\n",
        "        ball = np.full((ball_count), n+1) #1부터 시작\n",
        "        ball_box += list(ball)\n",
        "\n",
        "    selected_balls = []\n",
        "\n",
        "    while True:\n",
        "        \n",
        "        if len(selected_balls) == 6:\n",
        "            break\n",
        "        \n",
        "        ball_index = np.random.randint(len(ball_box), size=1)[0]\n",
        "        ball = ball_box[ball_index]\n",
        "\n",
        "        if ball not in selected_balls:\n",
        "            selected_balls.append(ball)\n",
        "\n",
        "    return selected_balls\n",
        "\n",
        "train_total_reward = []\n",
        "train_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "val_total_reward = []\n",
        "val_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "test_total_reward = []\n",
        "test_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "model.reset_states()\n",
        "\n",
        "print('[No. ] 1st 2nd 3rd 4th 5th 6th Rewards')\n",
        "\n",
        "for i in range(len(x_samples)):\n",
        "    xs = x_samples[i].reshape(1, 1, 45)\n",
        "    ys_pred = model.predict_on_batch(xs) # 모델의 출력값을 얻음\n",
        "    \n",
        "    sum_reward = 0\n",
        "    sum_grade = np.zeros(6, dtype=int) # 6등까지 변수\n",
        "\n",
        "    for n in range(10): # 10판 수행\n",
        "        numbers = gen_numbers_from_probability(ys_pred[0])\n",
        "        \n",
        "        #i회차 입력 후 나온 출력을 i+1회차와 비교함\n",
        "        grade, reward = calc_reward(rows[i+1,1:7], rows[i+1,7], numbers) \n",
        "\n",
        "        sum_reward += reward\n",
        "        sum_grade[grade] += 1\n",
        "\n",
        "        if i >= train_idx[0] and i < train_idx[1]:\n",
        "            train_total_grade[grade] += 1\n",
        "        elif i >= val_idx[0] and i < val_idx[1]:\n",
        "            val_total_grade[grade] += 1\n",
        "        elif i >= test_idx[0] and i < test_idx[1]:\n",
        "            val_total_grade[grade] += 1\n",
        "    \n",
        "    if i >= train_idx[0] and i < train_idx[1]:\n",
        "        train_total_reward.append(sum_reward)\n",
        "    elif i >= val_idx[0] and i < val_idx[1]:\n",
        "        val_total_reward.append(sum_reward)\n",
        "    elif i >= test_idx[0] and i < test_idx[1]:\n",
        "        test_total_reward.append(sum_reward)\n",
        "                        \n",
        "    print('[{0:4d}] {1:3d} {2:3d} {3:3d} {4:3d} {5:3d} {6:3d} {7:15,d}'.format(i+1, sum_grade[0], sum_grade[1], sum_grade[2], sum_grade[3], sum_grade[4], sum_grade[5], int(sum_reward)))\n",
        "\n",
        "print('Total') \n",
        "print('==========')    \n",
        "print('Train {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(train_total_grade[0], train_total_grade[1], train_total_grade[2], train_total_grade[3], train_total_grade[4], train_total_grade[5], int(sum(train_total_reward))))\n",
        "print('Val   {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(val_total_grade[0], val_total_grade[1], val_total_grade[2], val_total_grade[3], val_total_grade[4], val_total_grade[5], int(sum(val_total_reward))))\n",
        "print('Test  {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(test_total_grade[0], test_total_grade[1], test_total_grade[2], test_total_grade[3], test_total_grade[4], test_total_grade[5], int(sum(test_total_reward))))\n",
        "print('==========')    "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[No. ] 1st 2nd 3rd 4th 5th 6th Rewards\n",
            "[   1]   0   0   0   3   4   3         178,530\n",
            "[   2]   0   0   2   4   2   2       3,122,454\n",
            "[   3]   0   0   2   5   2   1       3,175,298\n",
            "[   4]   0   1   2   4   2   1      60,240,291\n",
            "[   5]   1   0   1   8   0   0   2,435,254,171\n",
            "[   6]   1   0   3   4   2   0   2,437,953,878\n",
            "[   7]   0   0   3   4   3   0       4,577,994\n",
            "[   8]   1   0   3   3   2   1   2,437,901,035\n",
            "[   9]   0   0   0   0   2   8          10,000\n",
            "[  10]   0   0   1   5   2   2       1,724,757\n",
            "[  11]   0   0   3   3   4   0       4,530,151\n",
            "[  12]   0   0   0   1   4   5          72,843\n",
            "[  13]   0   0   1   0   4   5       1,470,540\n",
            "[  14]   0   0   1   2   2   5       1,566,227\n",
            "[  15]   0   0   0   5   3   2         279,217\n",
            "[  16]   0   0   1   4   5   0       1,686,914\n",
            "[  17]   0   0   0   0   4   6          20,000\n",
            "[  18]   0   0   1   3   6   0       1,639,070\n",
            "[  19]   0   0   0   2   5   3         130,686\n",
            "[  20]   0   0   1   0   5   4       1,475,540\n",
            "[  21]   0   0   2   5   3   0       3,180,298\n",
            "[  22]   0   0   0   4   3   3         226,373\n",
            "[  23]   0   0   1   2   4   3       1,576,227\n",
            "[  24]   0   0   2   3   2   3       3,069,611\n",
            "[  25]   0   0   1   4   2   3       1,671,914\n",
            "[  26]   0   0   1   3   2   4       1,619,070\n",
            "[  27]   0   0   1   3   3   3       1,624,070\n",
            "[  28]   0   0   0   2   5   3         130,686\n",
            "[  29]   0   0   2   4   4   0       3,132,454\n",
            "[  30]   0   0   0   4   3   3         226,373\n",
            "[  31]   0   0   1   3   3   3       1,624,070\n",
            "[  32]   0   0   1   2   6   1       1,586,227\n",
            "[  33]   0   0   2   1   5   2       2,978,924\n",
            "[  34]   0   0   3   3   2   2       4,520,151\n",
            "[  35]   0   0   0   2   6   2         135,686\n",
            "[  36]   0   0   0   1   1   8          57,843\n",
            "[  37]   0   2   1   4   3   0     115,912,587\n",
            "[  38]   0   0   1   4   2   3       1,671,914\n",
            "[  39]   0   0   0   2   6   2         135,686\n",
            "[  40]   0   0   3   3   4   0       4,530,151\n",
            "[  41]   0   0   1   2   4   3       1,576,227\n",
            "[  42]   0   0   1   2   3   4       1,571,227\n",
            "[  43]   0   0   1   3   6   0       1,639,070\n",
            "[  44]   0   0   0   4   4   2         231,373\n",
            "[  45]   1   0   0   5   2   2   2,433,655,101\n",
            "[  46]   1   0   0   4   4   1   2,433,612,257\n",
            "[  47]   1   0   1   5   2   1   2,435,105,641\n",
            "[  48]   0   0   1   6   1   2       1,772,601\n",
            "[  49]   1   0   0   2   6   1   2,433,516,570\n",
            "[  50]   0   0   1   4   5   0       1,686,914\n",
            "[  51]   0   0   2   6   1   1       3,223,141\n",
            "[  52]   0   0   1   2   4   3       1,576,227\n",
            "[  53]   0   0   1   6   2   1       1,777,601\n",
            "[  54]   0   0   1   3   4   2       1,629,070\n",
            "[  55]   0   0   1   4   5   0       1,686,914\n",
            "[  56]   0   0   2   4   2   2       3,122,454\n",
            "[  57]   0   0   2   4   4   0       3,132,454\n",
            "[  58]   0   0   0   2   5   3         130,686\n",
            "[  59]   0   0   1   5   3   1       1,729,757\n",
            "[  60]   0   0   2   2   3   3       3,021,767\n",
            "[  61]   0   0   2   5   1   2       3,170,298\n",
            "[  62]   0   0   0   3   5   2         183,530\n",
            "[  63]   0   0   3   4   1   2       4,567,994\n",
            "[  64]   0   0   2   5   2   1       3,175,298\n",
            "[  65]   0   0   0   5   4   1         284,217\n",
            "[  66]   0   0   0   4   4   2         231,373\n",
            "[  67]   0   0   1   3   5   1       1,634,070\n",
            "[  68]   0   0   0   1   6   3          82,843\n",
            "[  69]   0   0   1   6   3   0       1,782,601\n",
            "[  70]   0   0   3   4   3   0       4,577,994\n",
            "[  71]   0   0   0   5   2   3         274,217\n",
            "[  72]   0   0   1   3   6   0       1,639,070\n",
            "[  73]   0   0   2   1   6   1       2,983,924\n",
            "[  74]   0   1   0   4   4   1      57,349,210\n",
            "[  75]   0   0   1   5   3   1       1,729,757\n",
            "[  76]   0   0   1   4   3   2       1,676,914\n",
            "[  77]   0   0   0   2   3   5         120,686\n",
            "[  78]   0   0   0   1   6   3          82,843\n",
            "[  79]   0   0   0   1   5   4          77,843\n",
            "[  80]   0   0   0   0   9   1          45,000\n",
            "[  81]   0   0   2   3   5   0       3,084,611\n",
            "[  82]   0   0   1   4   5   0       1,686,914\n",
            "[  83]   0   1   2   2   1   4      60,129,604\n",
            "[  84]   0   0   0   2   6   2         135,686\n",
            "[  85]   0   0   0   1   2   7          62,843\n",
            "[  86]   0   0   0   2   4   4         125,686\n",
            "[  87]   0   0   0   1   5   4          77,843\n",
            "[  88]   0   0   0   4   3   3         226,373\n",
            "[  89]   0   0   0   4   4   2         231,373\n",
            "[  90]   0   0   2   3   4   1       3,079,611\n",
            "[  91]   0   0   1   3   6   0       1,639,070\n",
            "[  92]   0   0   0   2   3   5         120,686\n",
            "[  93]   0   0   0   2   3   5         120,686\n",
            "[  94]   0   0   1   0   4   5       1,470,540\n",
            "[  95]   0   0   0   0   3   7          15,000\n",
            "[  96]   0   0   0   4   2   4         221,373\n",
            "[  97]   0   0   2   2   2   4       3,016,767\n",
            "[  98]   0   0   1   3   4   2       1,629,070\n",
            "[  99]   0   0   0   3   6   1         188,530\n",
            "[ 100]   0   0   1   1   3   5       1,518,383\n",
            "[ 101]   0   0   0   1   6   3          82,843\n",
            "[ 102]   1   0   2   3   2   2   2,436,450,494\n",
            "[ 103]   0   0   2   3   3   2       3,074,611\n",
            "[ 104]   0   0   0   2   3   5         120,686\n",
            "[ 105]   0   0   1   4   3   2       1,676,914\n",
            "[ 106]   0   0   2   4   3   1       3,127,454\n",
            "[ 107]   0   1   1   2   6   0      58,704,063\n",
            "[ 108]   0   0   1   3   5   1       1,634,070\n",
            "[ 109]   0   0   1   5   0   4       1,714,757\n",
            "[ 110]   0   0   1   5   2   2       1,724,757\n",
            "[ 111]   0   0   2   1   1   6       2,958,924\n",
            "[ 112]   0   0   0   1   6   3          82,843\n",
            "[ 113]   0   0   0   2   5   3         130,686\n",
            "[ 114]   0   0   0   2   3   5         120,686\n",
            "[ 115]   0   0   0   1   5   4          77,843\n",
            "[ 116]   0   0   0   3   4   3         178,530\n",
            "[ 117]   0   0   0   4   2   4         221,373\n",
            "[ 118]   0   0   0   1   3   6          67,843\n",
            "[ 119]   0   0   0   2   5   3         130,686\n",
            "[ 120]   0   0   1   4   4   1       1,681,914\n",
            "[ 121]   0   0   0   0   5   5          25,000\n",
            "[ 122]   0   0   1   0   3   6       1,465,540\n",
            "[ 123]   0   0   0   1   3   6          67,843\n",
            "[ 124]   0   0   1   3   5   1       1,634,070\n",
            "[ 125]   0   0   0   4   1   5         216,373\n",
            "[ 126]   0   0   0   2   5   3         130,686\n",
            "[ 127]   0   0   0   1   2   7          62,843\n",
            "[ 128]   0   0   0   1   5   4          77,843\n",
            "[ 129]   0   0   0   3   1   6         163,530\n",
            "[ 130]   0   0   2   1   3   4       2,968,924\n",
            "[ 131]   0   0   0   2   3   5         120,686\n",
            "[ 132]   0   0   0   2   7   1         140,686\n",
            "[ 133]   0   0   0   3   4   3         178,530\n",
            "[ 134]   0   0   0   1   4   5          72,843\n",
            "[ 135]   0   0   0   2   4   4         125,686\n",
            "[ 136]   0   0   1   2   4   3       1,576,227\n",
            "[ 137]   0   0   0   0   1   9           5,000\n",
            "[ 138]   0   0   0   0   5   5          25,000\n",
            "[ 139]   0   0   2   3   2   3       3,069,611\n",
            "[ 140]   0   0   0   1   5   4          77,843\n",
            "[ 141]   0   0   0   0   8   2          40,000\n",
            "[ 142]   0   0   1   1   4   4       1,523,383\n",
            "[ 143]   0   0   1   2   1   6       1,561,227\n",
            "[ 144]   0   0   0   3   0   7         158,530\n",
            "[ 145]   0   0   0   1   3   6          67,843\n",
            "[ 146]   0   0   0   1   2   7          62,843\n",
            "[ 147]   0   0   0   2   4   4         125,686\n",
            "[ 148]   0   0   0   4   3   3         226,373\n",
            "[ 149]   0   0   0   1   5   4          77,843\n",
            "[ 150]   0   0   0   1   1   8          57,843\n",
            "[ 151]   0   0   0   2   3   5         120,686\n",
            "[ 152]   0   0   1   2   3   4       1,571,227\n",
            "[ 153]   0   0   2   3   1   4       3,064,611\n",
            "[ 154]   0   0   0   1   4   5          72,843\n",
            "[ 155]   0   1   0   3   4   2      57,296,366\n",
            "[ 156]   0   0   1   1   3   5       1,518,383\n",
            "[ 157]   0   0   1   3   5   1       1,634,070\n",
            "[ 158]   0   0   0   3   3   4         173,530\n",
            "[ 159]   0   0   1   1   4   4       1,523,383\n",
            "[ 160]   0   0   0   4   2   4         221,373\n",
            "[ 161]   0   0   0   2   1   7         110,686\n",
            "[ 162]   0   0   2   4   3   1       3,127,454\n",
            "[ 163]   0   0   0   2   4   4         125,686\n",
            "[ 164]   0   0   0   0   4   6          20,000\n",
            "[ 165]   0   0   0   5   4   1         284,217\n",
            "[ 166]   0   0   0   2   4   4         125,686\n",
            "[ 167]   0   0   0   2   4   4         125,686\n",
            "[ 168]   0   0   1   4   4   1       1,681,914\n",
            "[ 169]   0   0   1   4   5   0       1,686,914\n",
            "[ 170]   0   0   1   0   5   4       1,475,540\n",
            "[ 171]   0   0   1   4   1   4       1,666,914\n",
            "[ 172]   0   0   1   1   4   4       1,523,383\n",
            "[ 173]   0   0   0   2   7   1         140,686\n",
            "[ 174]   0   0   0   0   1   9           5,000\n",
            "[ 175]   0   0   0   2   3   5         120,686\n",
            "[ 176]   0   0   2   3   3   2       3,074,611\n",
            "[ 177]   0   0   1   4   2   3       1,671,914\n",
            "[ 178]   0   0   1   2   5   2       1,581,227\n",
            "[ 179]   0   0   0   3   3   4         173,530\n",
            "[ 180]   0   0   0   4   2   4         221,373\n",
            "[ 181]   0   0   1   6   1   2       1,772,601\n",
            "[ 182]   0   0   0   1   0   9          52,843\n",
            "[ 183]   0   0   1   2   6   1       1,586,227\n",
            "[ 184]   0   0   0   1   4   5          72,843\n",
            "[ 185]   0   0   0   0   2   8          10,000\n",
            "[ 186]   0   0   0   0   6   4          30,000\n",
            "[ 187]   0   0   0   1   4   5          72,843\n",
            "[ 188]   0   0   0   4   4   2         231,373\n",
            "[ 189]   0   0   0   4   3   3         226,373\n",
            "[ 190]   0   0   3   3   1   3       4,515,151\n",
            "[ 191]   0   0   0   2   5   3         130,686\n",
            "[ 192]   0   0   0   1   1   8          57,843\n",
            "[ 193]   0   0   0   0   4   6          20,000\n",
            "[ 194]   0   0   0   2   6   2         135,686\n",
            "[ 195]   0   0   0   1   3   6          67,843\n",
            "[ 196]   0   0   0   2   7   1         140,686\n",
            "[ 197]   0   0   0   4   2   4         221,373\n",
            "[ 198]   0   0   0   3   4   3         178,530\n",
            "[ 199]   0   0   1   2   4   3       1,576,227\n",
            "[ 200]   0   0   0   2   2   6         115,686\n",
            "[ 201]   0   0   0   1   4   5          72,843\n",
            "[ 202]   0   0   0   0   1   9           5,000\n",
            "[ 203]   0   0   0   3   4   3         178,530\n",
            "[ 204]   0   0   0   0   6   4          30,000\n",
            "[ 205]   0   0   1   1   3   5       1,518,383\n",
            "[ 206]   0   0   0   3   5   2         183,530\n",
            "[ 207]   0   0   0   3   6   1         188,530\n",
            "[ 208]   0   0   2   1   6   1       2,983,924\n",
            "[ 209]   0   0   0   0   4   6          20,000\n",
            "[ 210]   0   0   1   0   5   4       1,475,540\n",
            "[ 211]   0   0   0   0   2   8          10,000\n",
            "[ 212]   0   0   0   2   6   2         135,686\n",
            "[ 213]   0   0   0   0   8   2          40,000\n",
            "[ 214]   0   0   0   4   2   4         221,373\n",
            "[ 215]   0   0   1   1   6   2       1,533,383\n",
            "[ 216]   0   0   0   3   5   2         183,530\n",
            "[ 217]   0   0   0   2   2   6         115,686\n",
            "[ 218]   0   0   0   0   2   8          10,000\n",
            "[ 219]   0   0   0   3   3   4         173,530\n",
            "[ 220]   0   0   0   2   1   7         110,686\n",
            "[ 221]   0   0   0   0   4   6          20,000\n",
            "[ 222]   0   0   0   1   4   5          72,843\n",
            "[ 223]   0   0   0   3   5   2         183,530\n",
            "[ 224]   0   0   0   4   2   4         221,373\n",
            "[ 225]   0   0   3   4   3   0       4,577,994\n",
            "[ 226]   0   0   0   1   3   6          67,843\n",
            "[ 227]   0   0   0   1   7   2          87,843\n",
            "[ 228]   0   0   1   1   4   4       1,523,383\n",
            "[ 229]   0   0   0   3   5   2         183,530\n",
            "[ 230]   0   0   0   3   5   2         183,530\n",
            "[ 231]   0   0   0   2   4   4         125,686\n",
            "[ 232]   1   0   0   3   5   1   2,433,564,414\n",
            "[ 233]   0   0   1   2   5   2       1,581,227\n",
            "[ 234]   0   0   0   4   3   3         226,373\n",
            "[ 235]   0   0   0   1   1   8          57,843\n",
            "[ 236]   0   0   0   1   3   6          67,843\n",
            "[ 237]   0   0   1   1   2   6       1,513,383\n",
            "[ 238]   0   0   0   1   3   6          67,843\n",
            "[ 239]   0   0   0   2   5   3         130,686\n",
            "[ 240]   0   0   0   3   6   1         188,530\n",
            "[ 241]   0   0   0   3   4   3         178,530\n",
            "[ 242]   0   0   0   5   2   3         274,217\n",
            "[ 243]   0   0   1   0   2   7       1,460,540\n",
            "[ 244]   0   0   0   2   4   4         125,686\n",
            "[ 245]   0   0   0   1   6   3          82,843\n",
            "[ 246]   0   0   0   4   3   3         226,373\n",
            "[ 247]   0   0   0   4   2   4         221,373\n",
            "[ 248]   0   0   0   3   5   2         183,530\n",
            "[ 249]   0   0   1   0   5   4       1,475,540\n",
            "[ 250]   0   0   0   3   3   4         173,530\n",
            "[ 251]   0   0   0   3   5   2         183,530\n",
            "[ 252]   0   0   0   2   4   4         125,686\n",
            "[ 253]   0   0   0   1   3   6          67,843\n",
            "[ 254]   0   0   1   1   5   3       1,528,383\n",
            "[ 255]   0   0   0   3   1   6         163,530\n",
            "[ 256]   0   0   0   1   2   7          62,843\n",
            "[ 257]   0   0   1   1   5   3       1,528,383\n",
            "[ 258]   0   0   0   1   3   6          67,843\n",
            "[ 259]   0   0   1   3   4   2       1,629,070\n",
            "[ 260]   0   0   0   1   2   7          62,843\n",
            "[ 261]   0   0   0   2   6   2         135,686\n",
            "[ 262]   0   0   0   2   4   4         125,686\n",
            "[ 263]   0   0   1   2   4   3       1,576,227\n",
            "[ 264]   0   0   0   5   3   2         279,217\n",
            "[ 265]   0   0   1   0   3   6       1,465,540\n",
            "[ 266]   0   0   1   5   2   2       1,724,757\n",
            "[ 267]   0   0   0   1   5   4          77,843\n",
            "[ 268]   0   0   0   2   5   3         130,686\n",
            "[ 269]   0   0   0   1   5   4          77,843\n",
            "[ 270]   0   0   0   2   7   1         140,686\n",
            "[ 271]   0   0   0   2   3   5         120,686\n",
            "[ 272]   0   0   0   0   1   9           5,000\n",
            "[ 273]   0   0   0   1   5   4          77,843\n",
            "[ 274]   0   0   1   1   6   2       1,533,383\n",
            "[ 275]   0   0   1   1   6   2       1,533,383\n",
            "[ 276]   0   0   0   0   1   9           5,000\n",
            "[ 277]   0   0   0   0   2   8          10,000\n",
            "[ 278]   0   0   0   6   1   3         322,060\n",
            "[ 279]   0   0   0   2   6   2         135,686\n",
            "[ 280]   1   0   1   4   4   0   2,435,062,797\n",
            "[ 281]   0   0   0   4   3   3         226,373\n",
            "[ 282]   0   0   0   0   3   7          15,000\n",
            "[ 283]   0   0   0   2   4   4         125,686\n",
            "[ 284]   0   0   0   0   4   6          20,000\n",
            "[ 285]   0   0   0   3   5   2         183,530\n",
            "[ 286]   0   0   0   5   4   1         284,217\n",
            "[ 287]   0   0   0   1   6   3          82,843\n",
            "[ 288]   0   0   0   2   5   3         130,686\n",
            "[ 289]   0   0   1   1   8   0       1,543,383\n",
            "[ 290]   0   0   2   3   4   1       3,079,611\n",
            "[ 291]   0   0   2   1   4   3       2,973,924\n",
            "[ 292]   0   0   1   0   5   4       1,475,540\n",
            "[ 293]   0   0   0   1   7   2          87,843\n",
            "[ 294]   0   0   0   7   3   0         384,904\n",
            "[ 295]   0   0   0   5   4   1         284,217\n",
            "[ 296]   0   0   0   1   0   9          52,843\n",
            "[ 297]   0   0   1   3   3   3       1,624,070\n",
            "[ 298]   0   0   0   0   5   5          25,000\n",
            "[ 299]   0   0   0   6   4   0         337,060\n",
            "[ 300]   0   0   0   2   2   6         115,686\n",
            "[ 301]   0   0   0   0   4   6          20,000\n",
            "[ 302]   0   0   1   0   4   5       1,470,540\n",
            "[ 303]   0   0   0   3   3   4         173,530\n",
            "[ 304]   0   0   1   2   4   3       1,576,227\n",
            "[ 305]   0   0   1   1   5   3       1,528,383\n",
            "[ 306]   0   0   0   1   4   5          72,843\n",
            "[ 307]   0   0   0   5   2   3         274,217\n",
            "[ 308]   0   0   0   5   5   0         289,217\n",
            "[ 309]   0   0   1   1   2   6       1,513,383\n",
            "[ 310]   0   0   0   0   2   8          10,000\n",
            "[ 311]   0   0   0   0   1   9           5,000\n",
            "[ 312]   0   0   0   1   2   7          62,843\n",
            "[ 313]   0   0   0   0   2   8          10,000\n",
            "[ 314]   0   0   0   1   6   3          82,843\n",
            "[ 315]   0   0   0   2   3   5         120,686\n",
            "[ 316]   0   0   0   4   4   2         231,373\n",
            "[ 317]   0   0   0   0   3   7          15,000\n",
            "[ 318]   0   0   0   0   3   7          15,000\n",
            "[ 319]   0   0   0   1   2   7          62,843\n",
            "[ 320]   1   0   0   4   3   2   2,433,607,257\n",
            "[ 321]   0   0   1   0   7   2       1,485,540\n",
            "[ 322]   0   0   0   0   2   8          10,000\n",
            "[ 323]   0   0   0   0   5   5          25,000\n",
            "[ 324]   0   0   0   2   4   4         125,686\n",
            "[ 325]   0   0   0   1   2   7          62,843\n",
            "[ 326]   0   0   0   3   3   4         173,530\n",
            "[ 327]   0   0   0   1   4   5          72,843\n",
            "[ 328]   0   0   1   3   2   4       1,619,070\n",
            "[ 329]   0   0   0   1   4   5          72,843\n",
            "[ 330]   0   0   0   1   4   5          72,843\n",
            "[ 331]   0   0   0   2   4   4         125,686\n",
            "[ 332]   0   0   0   3   4   3         178,530\n",
            "[ 333]   0   0   0   2   4   4         125,686\n",
            "[ 334]   0   0   0   1   6   3          82,843\n",
            "[ 335]   0   0   1   3   5   1       1,634,070\n",
            "[ 336]   0   0   0   0   2   8          10,000\n",
            "[ 337]   0   0   0   1   7   2          87,843\n",
            "[ 338]   0   0   0   3   7   0         193,530\n",
            "[ 339]   0   0   0   2   7   1         140,686\n",
            "[ 340]   0   0   0   0   4   6          20,000\n",
            "[ 341]   0   0   0   0   2   8          10,000\n",
            "[ 342]   0   0   0   1   1   8          57,843\n",
            "[ 343]   0   0   0   1   4   5          72,843\n",
            "[ 344]   0   0   0   3   3   4         173,530\n",
            "[ 345]   0   0   0   0   4   6          20,000\n",
            "[ 346]   0   0   0   2   6   2         135,686\n",
            "[ 347]   0   0   1   0   5   4       1,475,540\n",
            "[ 348]   0   0   0   2   4   4         125,686\n",
            "[ 349]   0   0   0   5   4   1         284,217\n",
            "[ 350]   0   0   1   3   5   1       1,634,070\n",
            "[ 351]   0   0   1   0   6   3       1,480,540\n",
            "[ 352]   0   0   1   3   2   4       1,619,070\n",
            "[ 353]   0   0   1   5   3   1       1,729,757\n",
            "[ 354]   0   0   0   3   5   2         183,530\n",
            "[ 355]   0   0   0   0   2   8          10,000\n",
            "[ 356]   0   0   2   1   5   2       2,978,924\n",
            "[ 357]   0   0   0   1   5   4          77,843\n",
            "[ 358]   0   0   0   0   5   5          25,000\n",
            "[ 359]   0   0   0   1   4   5          72,843\n",
            "[ 360]   0   0   0   0   2   8          10,000\n",
            "[ 361]   0   0   0   1   6   3          82,843\n",
            "[ 362]   0   0   0   2   5   3         130,686\n",
            "[ 363]   0   0   0   1   8   1          92,843\n",
            "[ 364]   0   0   0   1   4   5          72,843\n",
            "[ 365]   0   0   0   1   4   5          72,843\n",
            "[ 366]   0   0   0   1   6   3          82,843\n",
            "[ 367]   0   0   0   0   4   6          20,000\n",
            "[ 368]   0   0   0   3   4   3         178,530\n",
            "[ 369]   0   0   1   2   3   4       1,571,227\n",
            "[ 370]   0   0   0   4   2   4         221,373\n",
            "[ 371]   0   0   0   1   7   2          87,843\n",
            "[ 372]   0   0   0   3   4   3         178,530\n",
            "[ 373]   0   0   0   1   5   4          77,843\n",
            "[ 374]   0   0   0   1   2   7          62,843\n",
            "[ 375]   0   0   0   5   2   3         274,217\n",
            "[ 376]   0   0   1   2   3   4       1,571,227\n",
            "[ 377]   0   0   0   0   3   7          15,000\n",
            "[ 378]   0   0   0   1   7   2          87,843\n",
            "[ 379]   0   0   0   6   3   1         332,060\n",
            "[ 380]   0   0   0   0   2   8          10,000\n",
            "[ 381]   0   0   0   0   1   9           5,000\n",
            "[ 382]   0   0   0   2   6   2         135,686\n",
            "[ 383]   0   0   1   2   5   2       1,581,227\n",
            "[ 384]   0   0   1   3   5   1       1,634,070\n",
            "[ 385]   0   0   0   1   3   6          67,843\n",
            "[ 386]   0   0   0   1   2   7          62,843\n",
            "[ 387]   0   0   0   1   3   6          67,843\n",
            "[ 388]   0   0   0   3   4   3         178,530\n",
            "[ 389]   0   0   0   0   5   5          25,000\n",
            "[ 390]   0   0   1   3   2   4       1,619,070\n",
            "[ 391]   0   0   1   2   4   3       1,576,227\n",
            "[ 392]   0   0   0   4   4   2         231,373\n",
            "[ 393]   0   0   0   0   6   4          30,000\n",
            "[ 394]   0   0   0   2   3   5         120,686\n",
            "[ 395]   0   0   0   1   5   4          77,843\n",
            "[ 396]   0   0   0   3   6   1         188,530\n",
            "[ 397]   0   0   1   0   3   6       1,465,540\n",
            "[ 398]   0   0   2   4   1   3       3,117,454\n",
            "[ 399]   0   0   0   2   5   3         130,686\n",
            "[ 400]   0   0   0   3   2   5         168,530\n",
            "[ 401]   0   0   1   1   2   6       1,513,383\n",
            "[ 402]   0   0   0   1   5   4          77,843\n",
            "[ 403]   0   0   0   1   5   4          77,843\n",
            "[ 404]   0   0   1   3   3   3       1,624,070\n",
            "[ 405]   0   0   1   1   4   4       1,523,383\n",
            "[ 406]   0   0   0   0   2   8          10,000\n",
            "[ 407]   0   0   2   3   4   1       3,079,611\n",
            "[ 408]   0   0   0   2   7   1         140,686\n",
            "[ 409]   0   0   0   0   3   7          15,000\n",
            "[ 410]   0   0   0   2   3   5         120,686\n",
            "[ 411]   0   0   0   2   5   3         130,686\n",
            "[ 412]   0   0   0   1   1   8          57,843\n",
            "[ 413]   0   0   0   4   3   3         226,373\n",
            "[ 414]   0   0   0   0   1   9           5,000\n",
            "[ 415]   0   0   0   5   2   3         274,217\n",
            "[ 416]   0   0   0   1   2   7          62,843\n",
            "[ 417]   0   0   0   0   1   9           5,000\n",
            "[ 418]   0   0   1   2   2   5       1,566,227\n",
            "[ 419]   0   0   0   0   3   7          15,000\n",
            "[ 420]   0   0   0   2   3   5         120,686\n",
            "[ 421]   0   0   0   0   2   8          10,000\n",
            "[ 422]   0   0   0   0   2   8          10,000\n",
            "[ 423]   0   0   0   0   4   6          20,000\n",
            "[ 424]   0   0   0   3   3   4         173,530\n",
            "[ 425]   0   0   0   0   0  10               0\n",
            "[ 426]   0   0   0   0   4   6          20,000\n",
            "[ 427]   0   0   0   1   5   4          77,843\n",
            "[ 428]   0   0   0   0   0  10               0\n",
            "[ 429]   0   0   0   1   1   8          57,843\n",
            "[ 430]   0   0   0   0   1   9           5,000\n",
            "[ 431]   0   0   0   0   3   7          15,000\n",
            "[ 432]   0   0   0   5   3   2         279,217\n",
            "[ 433]   0   0   0   3   4   3         178,530\n",
            "[ 434]   0   0   2   2   5   1       3,031,767\n",
            "[ 435]   0   0   0   1   3   6          67,843\n",
            "[ 436]   0   0   0   2   4   4         125,686\n",
            "[ 437]   0   0   0   1   2   7          62,843\n",
            "[ 438]   0   0   1   2   3   4       1,571,227\n",
            "[ 439]   0   0   1   6   1   2       1,772,601\n",
            "[ 440]   1   0   1   4   1   3   2,435,047,797\n",
            "[ 441]   0   0   0   5   3   2         279,217\n",
            "[ 442]   0   0   0   0   6   4          30,000\n",
            "[ 443]   0   0   0   1   5   4          77,843\n",
            "[ 444]   0   0   0   3   3   4         173,530\n",
            "[ 445]   0   0   0   0   4   6          20,000\n",
            "[ 446]   0   0   0   0   2   8          10,000\n",
            "[ 447]   0   0   0   1   4   5          72,843\n",
            "[ 448]   0   0   0   6   2   2         327,060\n",
            "[ 449]   0   0   0   2   6   2         135,686\n",
            "[ 450]   0   0   0   0   4   6          20,000\n",
            "[ 451]   0   0   0   2   2   6         115,686\n",
            "[ 452]   0   0   0   1   2   7          62,843\n",
            "[ 453]   0   0   0   0   2   8          10,000\n",
            "[ 454]   0   0   1   0   4   5       1,470,540\n",
            "[ 455]   0   0   0   2   3   5         120,686\n",
            "[ 456]   0   0   1   0   4   5       1,470,540\n",
            "[ 457]   0   0   0   1   4   5          72,843\n",
            "[ 458]   0   0   0   2   8   0         145,686\n",
            "[ 459]   0   0   0   1   8   1          92,843\n",
            "[ 460]   0   0   0   0   4   6          20,000\n",
            "[ 461]   0   0   1   3   5   1       1,634,070\n",
            "[ 462]   0   0   0   1   5   4          77,843\n",
            "[ 463]   0   0   1   1   2   6       1,513,383\n",
            "[ 464]   0   0   0   1   5   4          77,843\n",
            "[ 465]   0   0   0   0   5   5          25,000\n",
            "[ 466]   0   0   0   2   3   5         120,686\n",
            "[ 467]   0   0   1   4   4   1       1,681,914\n",
            "[ 468]   0   0   0   1   4   5          72,843\n",
            "[ 469]   0   0   0   0   4   6          20,000\n",
            "[ 470]   0   0   1   3   6   0       1,639,070\n",
            "[ 471]   0   0   0   2   1   7         110,686\n",
            "[ 472]   0   0   0   3   3   4         173,530\n",
            "[ 473]   0   0   0   1   2   7          62,843\n",
            "[ 474]   0   0   0   3   2   5         168,530\n",
            "[ 475]   0   0   0   0   5   5          25,000\n",
            "[ 476]   0   0   0   0   0  10               0\n",
            "[ 477]   0   0   1   1   1   7       1,508,383\n",
            "[ 478]   0   0   0   0   4   6          20,000\n",
            "[ 479]   0   0   0   0   3   7          15,000\n",
            "[ 480]   0   0   0   1   6   3          82,843\n",
            "[ 481]   0   0   0   3   4   3         178,530\n",
            "[ 482]   0   0   0   3   3   4         173,530\n",
            "[ 483]   0   0   0   1   5   4          77,843\n",
            "[ 484]   0   0   0   1   3   6          67,843\n",
            "[ 485]   0   0   0   2   1   7         110,686\n",
            "[ 486]   0   0   0   0   2   8          10,000\n",
            "[ 487]   0   0   0   3   4   3         178,530\n",
            "[ 488]   0   0   0   0   7   3          35,000\n",
            "[ 489]   0   0   0   0   0  10               0\n",
            "[ 490]   0   0   0   2   2   6         115,686\n",
            "[ 491]   0   0   0   0   4   6          20,000\n",
            "[ 492]   0   0   0   1   1   8          57,843\n",
            "[ 493]   0   0   2   3   2   3       3,069,611\n",
            "[ 494]   0   0   0   3   3   4         173,530\n",
            "[ 495]   0   0   0   1   0   9          52,843\n",
            "[ 496]   0   0   1   1   6   2       1,533,383\n",
            "[ 497]   0   0   0   3   6   1         188,530\n",
            "[ 498]   0   1   0   0   4   5      57,137,836\n",
            "[ 499]   0   0   0   3   5   2         183,530\n",
            "[ 500]   0   0   1   2   5   2       1,581,227\n",
            "[ 501]   0   0   0   2   4   4         125,686\n",
            "[ 502]   0   0   0   2   5   3         130,686\n",
            "[ 503]   0   0   0   5   5   0         289,217\n",
            "[ 504]   0   0   0   3   4   3         178,530\n",
            "[ 505]   0   0   0   1   0   9          52,843\n",
            "[ 506]   0   0   0   0   3   7          15,000\n",
            "[ 507]   0   0   2   1   4   3       2,973,924\n",
            "[ 508]   0   0   1   3   4   2       1,629,070\n",
            "[ 509]   0   0   0   1   3   6          67,843\n",
            "[ 510]   0   0   0   1   6   3          82,843\n",
            "[ 511]   0   0   0   3   3   4         173,530\n",
            "[ 512]   0   0   1   2   4   3       1,576,227\n",
            "[ 513]   0   0   0   5   4   1         284,217\n",
            "[ 514]   0   0   3   3   2   2       4,520,151\n",
            "[ 515]   0   0   0   2   3   5         120,686\n",
            "[ 516]   0   0   1   5   4   0       1,734,757\n",
            "[ 517]   0   0   0   0   1   9           5,000\n",
            "[ 518]   0   0   0   1   2   7          62,843\n",
            "[ 519]   0   0   0   1   3   6          67,843\n",
            "[ 520]   0   0   3   4   2   1       4,572,994\n",
            "[ 521]   0   0   0   1   2   7          62,843\n",
            "[ 522]   0   0   0   2   5   3         130,686\n",
            "[ 523]   0   0   0   1   3   6          67,843\n",
            "[ 524]   0   0   1   2   4   3       1,576,227\n",
            "[ 525]   0   1   0   5   2   2      57,392,053\n",
            "[ 526]   0   0   0   2   4   4         125,686\n",
            "[ 527]   0   0   0   4   5   1         236,373\n",
            "[ 528]   0   0   0   6   3   1         332,060\n",
            "[ 529]   0   0   0   0   3   7          15,000\n",
            "[ 530]   0   0   0   4   4   2         231,373\n",
            "[ 531]   0   0   1   3   4   2       1,629,070\n",
            "[ 532]   0   0   3   4   3   0       4,577,994\n",
            "[ 533]   0   0   0   2   6   2         135,686\n",
            "[ 534]   0   0   1   5   4   0       1,734,757\n",
            "[ 535]   0   0   3   2   1   4       4,462,307\n",
            "[ 536]   0   0   1   3   3   3       1,624,070\n",
            "[ 537]   0   0   0   3   4   3         178,530\n",
            "[ 538]   0   0   0   2   4   4         125,686\n",
            "[ 539]   0   0   0   0   4   6          20,000\n",
            "[ 540]   0   0   0   1   3   6          67,843\n",
            "[ 541]   0   0   0   0   1   9           5,000\n",
            "[ 542]   0   0   0   1   7   2          87,843\n",
            "[ 543]   0   0   0   2   5   3         130,686\n",
            "[ 544]   0   0   0   0   2   8          10,000\n",
            "[ 545]   0   0   0   4   2   4         221,373\n",
            "[ 546]   0   0   0   1   3   6          67,843\n",
            "[ 547]   0   0   0   2   4   4         125,686\n",
            "[ 548]   0   0   0   2   2   6         115,686\n",
            "[ 549]   0   0   0   4   3   3         226,373\n",
            "[ 550]   0   0   0   0   5   5          25,000\n",
            "[ 551]   0   0   0   4   2   4         221,373\n",
            "[ 552]   0   0   0   3   4   3         178,530\n",
            "[ 553]   0   0   0   0   1   9           5,000\n",
            "[ 554]   0   0   0   3   3   4         173,530\n",
            "[ 555]   0   0   0   2   5   3         130,686\n",
            "[ 556]   0   0   0   3   3   4         173,530\n",
            "[ 557]   0   0   1   5   4   0       1,734,757\n",
            "[ 558]   0   0   0   1   4   5          72,843\n",
            "[ 559]   0   0   0   0   4   6          20,000\n",
            "[ 560]   0   0   0   0   5   5          25,000\n",
            "[ 561]   0   0   1   0   2   7       1,460,540\n",
            "[ 562]   0   0   2   3   3   2       3,074,611\n",
            "[ 563]   0   0   0   0   1   9           5,000\n",
            "[ 564]   0   0   0   0   2   8          10,000\n",
            "[ 565]   0   0   0   2   3   5         120,686\n",
            "[ 566]   0   0   0   0   4   6          20,000\n",
            "[ 567]   0   0   0   1   3   6          67,843\n",
            "[ 568]   0   0   1   3   4   2       1,629,070\n",
            "[ 569]   0   0   2   2   3   3       3,021,767\n",
            "[ 570]   0   0   1   5   2   2       1,724,757\n",
            "[ 571]   0   0   0   4   1   5         216,373\n",
            "[ 572]   0   0   0   1   5   4          77,843\n",
            "[ 573]   0   0   0   4   3   3         226,373\n",
            "[ 574]   0   0   0   2   4   4         125,686\n",
            "[ 575]   0   0   1   1   5   3       1,528,383\n",
            "[ 576]   0   0   0   1   4   5          72,843\n",
            "[ 577]   0   0   0   1   3   6          67,843\n",
            "[ 578]   0   0   0   0   2   8          10,000\n",
            "[ 579]   0   0   0   4   4   2         231,373\n",
            "[ 580]   0   0   0   2   4   4         125,686\n",
            "[ 581]   0   0   0   2   4   4         125,686\n",
            "[ 582]   0   0   0   5   4   1         284,217\n",
            "[ 583]   1   0   0   3   5   1   2,433,564,414\n",
            "[ 584]   0   0   0   0   4   6          20,000\n",
            "[ 585]   0   0   0   1   4   5          72,843\n",
            "[ 586]   0   0   1   2   2   5       1,566,227\n",
            "[ 587]   0   0   0   1   6   3          82,843\n",
            "[ 588]   0   0   0   0   3   7          15,000\n",
            "[ 589]   0   0   0   1   5   4          77,843\n",
            "[ 590]   0   0   0   1   6   3          82,843\n",
            "[ 591]   0   0   0   0   2   8          10,000\n",
            "[ 592]   0   0   0   0   3   7          15,000\n",
            "[ 593]   0   0   0   2   4   4         125,686\n",
            "[ 594]   0   0   0   1   2   7          62,843\n",
            "[ 595]   0   0   0   1   0   9          52,843\n",
            "[ 596]   0   0   0   1   4   5          72,843\n",
            "[ 597]   0   0   0   0   2   8          10,000\n",
            "[ 598]   0   0   0   2   8   0         145,686\n",
            "[ 599]   0   0   1   4   3   2       1,676,914\n",
            "[ 600]   0   0   0   1   1   8          57,843\n",
            "[ 601]   0   0   3   1   4   2       4,424,464\n",
            "[ 602]   0   0   1   2   6   1       1,586,227\n",
            "[ 603]   0   0   0   3   5   2         183,530\n",
            "[ 604]   0   0   0   1   4   5          72,843\n",
            "[ 605]   0   1   0   1   4   4      57,190,679\n",
            "[ 606]   0   0   0   0   3   7          15,000\n",
            "[ 607]   0   0   0   2   3   5         120,686\n",
            "[ 608]   0   0   0   1   3   6          67,843\n",
            "[ 609]   0   0   0   1   4   5          72,843\n",
            "[ 610]   0   0   0   3   3   4         173,530\n",
            "[ 611]   0   0   0   0   3   7          15,000\n",
            "[ 612]   0   0   0   4   4   2         231,373\n",
            "[ 613]   0   0   1   3   5   1       1,634,070\n",
            "[ 614]   0   0   0   0   2   8          10,000\n",
            "[ 615]   0   0   0   3   2   5         168,530\n",
            "[ 616]   0   0   1   2   5   2       1,581,227\n",
            "[ 617]   0   0   1   2   7   0       1,591,227\n",
            "[ 618]   0   0   2   2   4   2       3,026,767\n",
            "[ 619]   0   0   0   1   5   4          77,843\n",
            "[ 620]   0   0   1   5   4   0       1,734,757\n",
            "[ 621]   0   0   0   4   4   2         231,373\n",
            "[ 622]   0   0   1   3   4   2       1,629,070\n",
            "[ 623]   0   0   0   1   5   4          77,843\n",
            "[ 624]   0   0   1   3   5   1       1,634,070\n",
            "[ 625]   0   0   0   2   4   4         125,686\n",
            "[ 626]   0   0   0   0   1   9           5,000\n",
            "[ 627]   0   0   0   3   5   2         183,530\n",
            "[ 628]   0   0   0   1   6   3          82,843\n",
            "[ 629]   0   0   0   1   2   7          62,843\n",
            "[ 630]   0   0   0   1   2   7          62,843\n",
            "[ 631]   0   0   0   2   1   7         110,686\n",
            "[ 632]   0   0   0   0   1   9           5,000\n",
            "[ 633]   0   0   0   0   3   7          15,000\n",
            "[ 634]   0   0   0   0   3   7          15,000\n",
            "[ 635]   0   0   0   2   1   7         110,686\n",
            "[ 636]   0   0   1   2   4   3       1,576,227\n",
            "[ 637]   0   0   0   0   4   6          20,000\n",
            "[ 638]   0   0   1   0   3   6       1,465,540\n",
            "[ 639]   0   0   0   0   5   5          25,000\n",
            "[ 640]   0   0   0   2   4   4         125,686\n",
            "[ 641]   0   0   0   3   4   3         178,530\n",
            "[ 642]   0   0   0   0   1   9           5,000\n",
            "[ 643]   0   0   0   2   2   6         115,686\n",
            "[ 644]   0   0   0   1   7   2          87,843\n",
            "[ 645]   0   0   0   0   4   6          20,000\n",
            "[ 646]   0   0   0   3   1   6         163,530\n",
            "[ 647]   0   0   0   2   4   4         125,686\n",
            "[ 648]   0   0   0   1   2   7          62,843\n",
            "[ 649]   0   0   1   1   2   6       1,513,383\n",
            "[ 650]   0   0   0   2   5   3         130,686\n",
            "[ 651]   0   0   1   3   2   4       1,619,070\n",
            "[ 652]   0   0   2   2   4   2       3,026,767\n",
            "[ 653]   0   0   2   5   3   0       3,180,298\n",
            "[ 654]   0   0   3   4   2   1       4,572,994\n",
            "[ 655]   0   0   0   4   4   2         231,373\n",
            "[ 656]   0   0   0   2   5   3         130,686\n",
            "[ 657]   0   0   0   1   2   7          62,843\n",
            "[ 658]   0   0   0   6   2   2         327,060\n",
            "[ 659]   0   0   2   3   2   3       3,069,611\n",
            "[ 660]   0   0   0   0   7   3          35,000\n",
            "[ 661]   0   0   0   3   5   2         183,530\n",
            "[ 662]   0   0   0   4   4   2         231,373\n",
            "[ 663]   0   0   0   1   6   3          82,843\n",
            "[ 664]   0   0   1   5   4   0       1,734,757\n",
            "[ 665]   0   0   1   5   3   1       1,729,757\n",
            "[ 666]   0   1   3   2   3   1      61,590,144\n",
            "[ 667]   0   0   0   0   3   7          15,000\n",
            "[ 668]   0   0   0   2   2   6         115,686\n",
            "[ 669]   0   0   1   4   3   2       1,676,914\n",
            "[ 670]   0   0   0   1   9   0          97,843\n",
            "[ 671]   0   0   0   1   4   5          72,843\n",
            "[ 672]   0   0   1   0   6   3       1,480,540\n",
            "[ 673]   0   0   2   2   5   1       3,031,767\n",
            "[ 674]   0   0   1   1   4   4       1,523,383\n",
            "[ 675]   0   0   0   0   3   7          15,000\n",
            "[ 676]   0   0   0   4   5   1         236,373\n",
            "[ 677]   0   0   1   0   4   5       1,470,540\n",
            "[ 678]   0   0   1   1   5   3       1,528,383\n",
            "[ 679]   0   0   0   2   7   1         140,686\n",
            "[ 680]   0   0   0   1   6   3          82,843\n",
            "[ 681]   0   0   1   1   5   3       1,528,383\n",
            "[ 682]   0   0   0   2   4   4         125,686\n",
            "[ 683]   0   0   0   1   3   6          67,843\n",
            "[ 684]   0   0   2   3   5   0       3,084,611\n",
            "[ 685]   0   0   0   3   5   2         183,530\n",
            "[ 686]   0   0   0   4   2   4         221,373\n",
            "[ 687]   0   0   0   0   5   5          25,000\n",
            "[ 688]   0   0   2   1   4   3       2,973,924\n",
            "[ 689]   0   0   0   3   4   3         178,530\n",
            "[ 690]   0   0   0   5   4   1         284,217\n",
            "[ 691]   0   0   1   5   1   3       1,719,757\n",
            "[ 692]   0   0   1   1   3   5       1,518,383\n",
            "[ 693]   0   0   1   2   5   2       1,581,227\n",
            "[ 694]   0   0   0   0   3   7          15,000\n",
            "[ 695]   0   0   1   4   3   2       1,676,914\n",
            "[ 696]   0   0   0   5   3   2         279,217\n",
            "[ 697]   0   0   1   1   7   1       1,538,383\n",
            "[ 698]   0   0   2   2   2   4       3,016,767\n",
            "[ 699]   0   0   0   1   5   4          77,843\n",
            "[ 700]   0   0   2   4   3   1       3,127,454\n",
            "[ 701]   0   0   0   0   0  10               0\n",
            "[ 702]   0   0   0   0   1   9           5,000\n",
            "[ 703]   0   0   0   1   0   9          52,843\n",
            "[ 704]   0   0   0   0   0  10               0\n",
            "[ 705]   0   0   0   0   0  10               0\n",
            "[ 706]   0   0   0   0   0  10               0\n",
            "[ 707]   0   0   0   0   0  10               0\n",
            "[ 708]   0   0   0   0   0  10               0\n",
            "[ 709]   0   0   0   0   0  10               0\n",
            "[ 710]   0   0   0   0   2   8          10,000\n",
            "[ 711]   0   0   0   0   0  10               0\n",
            "[ 712]   0   0   0   0   0  10               0\n",
            "[ 713]   0   0   0   0   0  10               0\n",
            "[ 714]   0   0   0   0   0  10               0\n",
            "[ 715]   0   0   0   0   0  10               0\n",
            "[ 716]   0   0   0   0   1   9           5,000\n",
            "[ 717]   0   0   0   0   0  10               0\n",
            "[ 718]   0   0   0   0   0  10               0\n",
            "[ 719]   0   0   0   0   0  10               0\n",
            "[ 720]   0   0   0   0   0  10               0\n",
            "[ 721]   0   0   0   0   0  10               0\n",
            "[ 722]   0   0   0   0   0  10               0\n",
            "[ 723]   0   0   0   0   0  10               0\n",
            "[ 724]   0   0   0   0   0  10               0\n",
            "[ 725]   0   0   0   0   0  10               0\n",
            "[ 726]   0   0   0   0   1   9           5,000\n",
            "[ 727]   0   0   0   0   0  10               0\n",
            "[ 728]   0   0   0   0   0  10               0\n",
            "[ 729]   0   0   0   0   1   9           5,000\n",
            "[ 730]   0   0   0   0   0  10               0\n",
            "[ 731]   0   0   0   0   0  10               0\n",
            "[ 732]   0   0   0   0   0  10               0\n",
            "[ 733]   0   0   0   0   0  10               0\n",
            "[ 734]   0   0   0   0   0  10               0\n",
            "[ 735]   0   0   0   0   1   9           5,000\n",
            "[ 736]   0   0   0   0   0  10               0\n",
            "[ 737]   0   0   0   0   0  10               0\n",
            "[ 738]   0   0   0   0   0  10               0\n",
            "[ 739]   0   0   0   0   0  10               0\n",
            "[ 740]   0   0   0   0   0  10               0\n",
            "[ 741]   0   0   0   0   0  10               0\n",
            "[ 742]   0   0   0   0   0  10               0\n",
            "[ 743]   0   0   0   0   0  10               0\n",
            "[ 744]   0   0   0   0   0  10               0\n",
            "[ 745]   0   0   0   0   0  10               0\n",
            "[ 746]   0   0   0   0   1   9           5,000\n",
            "[ 747]   0   0   0   0   3   7          15,000\n",
            "[ 748]   0   0   0   0   1   9           5,000\n",
            "[ 749]   0   0   0   0   0  10               0\n",
            "[ 750]   0   0   0   0   0  10               0\n",
            "[ 751]   0   0   0   0   0  10               0\n",
            "[ 752]   0   0   0   0   0  10               0\n",
            "[ 753]   0   0   0   0   0  10               0\n",
            "[ 754]   0   0   0   0   0  10               0\n",
            "[ 755]   0   0   0   0   2   8          10,000\n",
            "[ 756]   0   0   0   0   0  10               0\n",
            "[ 757]   0   0   0   0   0  10               0\n",
            "[ 758]   0   0   0   0   0  10               0\n",
            "[ 759]   0   0   0   0   0  10               0\n",
            "[ 760]   0   0   0   0   0  10               0\n",
            "[ 761]   0   0   0   0   0  10               0\n",
            "[ 762]   0   0   0   0   1   9           5,000\n",
            "[ 763]   0   0   0   0   0  10               0\n",
            "[ 764]   0   0   0   0   0  10               0\n",
            "[ 765]   0   0   0   0   0  10               0\n",
            "[ 766]   0   0   0   0   0  10               0\n",
            "[ 767]   0   0   0   0   0  10               0\n",
            "[ 768]   0   0   0   0   0  10               0\n",
            "[ 769]   0   0   0   0   0  10               0\n",
            "[ 770]   0   0   0   0   2   8          10,000\n",
            "[ 771]   0   0   0   0   0  10               0\n",
            "[ 772]   0   0   0   0   0  10               0\n",
            "[ 773]   0   0   0   0   0  10               0\n",
            "[ 774]   0   0   0   0   1   9           5,000\n",
            "[ 775]   0   0   0   0   0  10               0\n",
            "[ 776]   0   0   0   0   2   8          10,000\n",
            "[ 777]   0   0   0   0   0  10               0\n",
            "[ 778]   0   0   0   0   0  10               0\n",
            "[ 779]   0   0   0   0   0  10               0\n",
            "[ 780]   0   0   0   0   0  10               0\n",
            "[ 781]   0   0   0   0   0  10               0\n",
            "[ 782]   0   0   0   0   1   9           5,000\n",
            "[ 783]   0   0   0   0   0  10               0\n",
            "[ 784]   0   0   0   0   0  10               0\n",
            "[ 785]   0   0   0   0   2   8          10,000\n",
            "[ 786]   0   0   0   0   0  10               0\n",
            "[ 787]   0   0   0   0   0  10               0\n",
            "[ 788]   0   0   0   0   1   9           5,000\n",
            "[ 789]   0   0   0   0   0  10               0\n",
            "[ 790]   0   0   0   0   0  10               0\n",
            "[ 791]   0   0   0   0   0  10               0\n",
            "[ 792]   0   0   0   0   0  10               0\n",
            "[ 793]   0   0   0   0   0  10               0\n",
            "[ 794]   0   0   0   0   0  10               0\n",
            "[ 795]   0   0   0   0   1   9           5,000\n",
            "[ 796]   0   0   0   0   0  10               0\n",
            "[ 797]   0   0   0   0   1   9           5,000\n",
            "[ 798]   0   0   0   0   0  10               0\n",
            "[ 799]   0   0   0   0   0  10               0\n",
            "[ 800]   0   0   0   0   0  10               0\n",
            "[ 801]   0   0   0   0   0  10               0\n",
            "[ 802]   0   0   0   0   0  10               0\n",
            "[ 803]   0   0   0   0   0  10               0\n",
            "[ 804]   0   0   0   0   0  10               0\n",
            "[ 805]   0   0   0   0   0  10               0\n",
            "[ 806]   0   0   0   0   1   9           5,000\n",
            "[ 807]   0   0   0   0   1   9           5,000\n",
            "[ 808]   0   0   0   0   0  10               0\n",
            "[ 809]   0   0   0   0   0  10               0\n",
            "[ 810]   0   0   0   0   0  10               0\n",
            "[ 811]   0   0   0   0   0  10               0\n",
            "[ 812]   0   0   0   0   0  10               0\n",
            "[ 813]   0   0   0   0   0  10               0\n",
            "[ 814]   0   0   0   0   2   8          10,000\n",
            "[ 815]   0   0   0   0   0  10               0\n",
            "[ 816]   0   0   0   0   0  10               0\n",
            "[ 817]   0   0   0   0   0  10               0\n",
            "[ 818]   0   0   0   0   2   8          10,000\n",
            "[ 819]   0   0   0   0   0  10               0\n",
            "[ 820]   0   0   0   0   0  10               0\n",
            "[ 821]   0   0   0   0   0  10               0\n",
            "[ 822]   0   0   0   0   0  10               0\n",
            "[ 823]   0   0   0   0   0  10               0\n",
            "[ 824]   0   0   0   0   0  10               0\n",
            "[ 825]   0   0   0   0   0  10               0\n",
            "[ 826]   0   0   0   0   1   9           5,000\n",
            "[ 827]   0   0   0   0   1   9           5,000\n",
            "[ 828]   0   0   0   0   0  10               0\n",
            "[ 829]   0   0   0   0   0  10               0\n",
            "[ 830]   0   0   0   0   2   8          10,000\n",
            "[ 831]   0   0   0   0   0  10               0\n",
            "[ 832]   0   0   0   0   0  10               0\n",
            "[ 833]   0   0   0   0   0  10               0\n",
            "[ 834]   0   0   0   0   1   9           5,000\n",
            "[ 835]   0   0   0   0   0  10               0\n",
            "[ 836]   0   0   0   0   0  10               0\n",
            "[ 837]   0   0   0   0   0  10               0\n",
            "[ 838]   0   0   0   0   0  10               0\n",
            "[ 839]   0   0   0   0   0  10               0\n",
            "[ 840]   0   0   0   0   0  10               0\n",
            "[ 841]   0   0   0   0   0  10               0\n",
            "[ 842]   0   0   0   0   0  10               0\n",
            "[ 843]   0   0   0   0   0  10               0\n",
            "[ 844]   0   0   0   0   0  10               0\n",
            "[ 845]   0   0   0   0   0  10               0\n",
            "[ 846]   0   0   0   0   0  10               0\n",
            "[ 847]   0   0   0   0   0  10               0\n",
            "[ 848]   0   0   0   0   1   9           5,000\n",
            "[ 849]   0   0   0   0   0  10               0\n",
            "[ 850]   0   0   0   0   0  10               0\n",
            "[ 851]   0   0   0   0   0  10               0\n",
            "[ 852]   0   0   0   0   0  10               0\n",
            "[ 853]   0   0   0   0   0  10               0\n",
            "[ 854]   0   0   0   0   0  10               0\n",
            "[ 855]   0   0   0   0   0  10               0\n",
            "[ 856]   0   0   0   0   0  10               0\n",
            "[ 857]   0   0   0   0   0  10               0\n",
            "[ 858]   0   0   0   0   0  10               0\n",
            "[ 859]   0   0   0   0   0  10               0\n",
            "[ 860]   0   0   0   0   0  10               0\n",
            "[ 861]   0   0   0   0   0  10               0\n",
            "[ 862]   0   0   0   0   0  10               0\n",
            "[ 863]   0   0   0   0   1   9           5,000\n",
            "[ 864]   0   0   0   0   0  10               0\n",
            "[ 865]   0   0   0   0   0  10               0\n",
            "[ 866]   0   0   0   0   0  10               0\n",
            "[ 867]   0   0   0   0   0  10               0\n",
            "[ 868]   0   0   0   0   0  10               0\n",
            "[ 869]   0   0   0   0   0  10               0\n",
            "[ 870]   0   0   0   0   0  10               0\n",
            "[ 871]   0   0   0   0   0  10               0\n",
            "[ 872]   0   0   0   0   1   9           5,000\n",
            "[ 873]   0   0   0   0   0  10               0\n",
            "[ 874]   0   0   0   0   0  10               0\n",
            "[ 875]   0   0   0   0   0  10               0\n",
            "[ 876]   0   0   0   0   1   9           5,000\n",
            "[ 877]   0   0   0   0   0  10               0\n",
            "[ 878]   0   0   0   0   0  10               0\n",
            "[ 879]   0   0   0   0   0  10               0\n",
            "[ 880]   0   0   0   0   0  10               0\n",
            "[ 881]   0   0   0   0   0  10               0\n",
            "[ 882]   0   0   0   0   0  10               0\n",
            "[ 883]   0   0   0   0   0  10               0\n",
            "[ 884]   0   0   0   0   0  10               0\n",
            "[ 885]   0   0   0   0   1   9           5,000\n",
            "[ 886]   0   0   0   0   1   9           5,000\n",
            "[ 887]   0   0   0   0   0  10               0\n",
            "[ 888]   0   0   0   0   0  10               0\n",
            "[ 889]   0   0   0   0   0  10               0\n",
            "[ 890]   0   0   0   0   0  10               0\n",
            "[ 891]   0   0   0   0   0  10               0\n",
            "[ 892]   0   0   0   0   0  10               0\n",
            "[ 893]   0   0   0   0   0  10               0\n",
            "[ 894]   0   0   0   0   1   9           5,000\n",
            "[ 895]   0   0   0   0   1   9           5,000\n",
            "[ 896]   0   0   0   0   0  10               0\n",
            "[ 897]   0   0   0   0   0  10               0\n",
            "[ 898]   0   0   0   0   0  10               0\n",
            "[ 899]   0   0   0   0   0  10               0\n",
            "[ 900]   0   0   0   0   0  10               0\n",
            "[ 901]   0   0   0   0   0  10               0\n",
            "[ 902]   0   0   0   0   0  10               0\n",
            "[ 903]   0   0   0   0   0  10               0\n",
            "[ 904]   0   0   0   0   0  10               0\n",
            "[ 905]   0   0   0   0   0  10               0\n",
            "[ 906]   0   0   0   0   0  10               0\n",
            "[ 907]   0   0   0   0   0  10               0\n",
            "[ 908]   0   0   0   0   0  10               0\n",
            "[ 909]   0   0   0   0   0  10               0\n",
            "[ 910]   0   0   0   0   0  10               0\n",
            "[ 911]   0   0   0   0   0  10               0\n",
            "[ 912]   0   0   0   0   0  10               0\n",
            "[ 913]   0   0   0   0   0  10               0\n",
            "[ 914]   0   0   0   0   0  10               0\n",
            "[ 915]   0   0   0   0   0  10               0\n",
            "[ 916]   0   0   0   0   0  10               0\n",
            "[ 917]   0   0   0   0   0  10               0\n",
            "[ 918]   0   0   0   0   0  10               0\n",
            "[ 919]   0   0   0   0   0  10               0\n",
            "[ 920]   0   0   0   0   0  10               0\n",
            "[ 921]   0   0   0   0   0  10               0\n",
            "[ 922]   0   0   0   0   0  10               0\n",
            "[ 923]   0   0   0   0   0  10               0\n",
            "[ 924]   0   0   0   0   0  10               0\n",
            "[ 925]   0   0   0   0   0  10               0\n",
            "[ 926]   0   0   0   0   0  10               0\n",
            "[ 927]   0   0   0   0   0  10               0\n",
            "[ 928]   0   0   0   0   0  10               0\n",
            "[ 929]   0   0   0   0   0  10               0\n",
            "[ 930]   0   0   0   0   0  10               0\n",
            "[ 931]   0   0   0   0   1   9           5,000\n",
            "[ 932]   0   0   0   0   0  10               0\n",
            "[ 933]   0   0   0   0   0  10               0\n",
            "[ 934]   0   0   0   0   1   9           5,000\n",
            "[ 935]   0   0   0   0   5   5          25,000\n",
            "[ 936]   0   0   0   0   0  10               0\n",
            "[ 937]   0   0   0   0   0  10               0\n",
            "[ 938]   0   0   0   0   2   8          10,000\n",
            "[ 939]   0   0   0   0   0  10               0\n",
            "[ 940]   0   0   0   0   0  10               0\n",
            "[ 941]   0   0   0   0   0  10               0\n",
            "[ 942]   0   0   0   0   0  10               0\n",
            "[ 943]   0   0   0   0   0  10               0\n",
            "[ 944]   0   0   0   0   1   9           5,000\n",
            "[ 945]   0   0   0   0   0  10               0\n",
            "[ 946]   0   0   0   0   0  10               0\n",
            "[ 947]   0   0   0   0   0  10               0\n",
            "[ 948]   0   0   0   0   0  10               0\n",
            "[ 949]   0   0   0   0   1   9           5,000\n",
            "[ 950]   0   0   0   0   0  10               0\n",
            "[ 951]   0   0   0   0   0  10               0\n",
            "[ 952]   0   0   0   0   2   8          10,000\n",
            "[ 953]   0   0   0   0   0  10               0\n",
            "[ 954]   0   0   0   0   0  10               0\n",
            "[ 955]   0   0   0   0   0  10               0\n",
            "Total\n",
            "==========\n",
            "Train    13    11   299  1425  2529  2723  32,783,906,193\n",
            "Val       0     0     0     1    58  2491         182,843\n",
            "Test      0     0     0     0     0     0         160,000\n",
            "==========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyJvMPVl5QV8",
        "outputId": "8532c95c-464d-4cfa-807c-a2e99431e665"
      },
      "source": [
        "# 최대 100번 에포크까지 수행\n",
        "for epoch in range(100):\n",
        "\n",
        "    model.reset_states() # 중요! 매 에포크마다 1회부터 다시 훈련하므로 상태 초기화 필요\n",
        "\n",
        "    for i in range(len(x_samples)):\n",
        "        \n",
        "        xs = x_samples[i].reshape(1, 1, 45)\n",
        "        ys = y_samples[i].reshape(1, 45)\n",
        "        \n",
        "        loss, acc = model.train_on_batch(xs, ys) #배치만큼 모델에 학습시킴\n",
        "\n",
        "        batch_train_loss.append(loss)\n",
        "        batch_train_acc.append(acc)\n",
        "\n",
        "    train_loss.append(np.mean(batch_train_loss))\n",
        "    train_acc.append(np.mean(batch_train_acc))\n",
        "\n",
        "    print('epoch {0:4d} train acc {1:0.3f} loss {2:0.3f}'.format(epoch, np.mean(batch_train_acc), np.mean(batch_train_loss)))  "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch    0 train acc 0.921 loss 0.240\n",
            "epoch    1 train acc 0.913 loss 0.254\n",
            "epoch    2 train acc 0.913 loss 0.250\n",
            "epoch    3 train acc 0.914 loss 0.244\n",
            "epoch    4 train acc 0.916 loss 0.238\n",
            "epoch    5 train acc 0.918 loss 0.233\n",
            "epoch    6 train acc 0.920 loss 0.228\n",
            "epoch    7 train acc 0.921 loss 0.223\n",
            "epoch    8 train acc 0.923 loss 0.218\n",
            "epoch    9 train acc 0.925 loss 0.213\n",
            "epoch   10 train acc 0.926 loss 0.209\n",
            "epoch   11 train acc 0.928 loss 0.205\n",
            "epoch   12 train acc 0.930 loss 0.201\n",
            "epoch   13 train acc 0.931 loss 0.197\n",
            "epoch   14 train acc 0.932 loss 0.193\n",
            "epoch   15 train acc 0.934 loss 0.190\n",
            "epoch   16 train acc 0.935 loss 0.186\n",
            "epoch   17 train acc 0.936 loss 0.183\n",
            "epoch   18 train acc 0.937 loss 0.180\n",
            "epoch   19 train acc 0.939 loss 0.177\n",
            "epoch   20 train acc 0.940 loss 0.174\n",
            "epoch   21 train acc 0.941 loss 0.171\n",
            "epoch   22 train acc 0.942 loss 0.168\n",
            "epoch   23 train acc 0.943 loss 0.165\n",
            "epoch   24 train acc 0.945 loss 0.162\n",
            "epoch   25 train acc 0.946 loss 0.159\n",
            "epoch   26 train acc 0.947 loss 0.157\n",
            "epoch   27 train acc 0.948 loss 0.154\n",
            "epoch   28 train acc 0.949 loss 0.152\n",
            "epoch   29 train acc 0.950 loss 0.149\n",
            "epoch   30 train acc 0.951 loss 0.147\n",
            "epoch   31 train acc 0.952 loss 0.145\n",
            "epoch   32 train acc 0.952 loss 0.143\n",
            "epoch   33 train acc 0.953 loss 0.141\n",
            "epoch   34 train acc 0.954 loss 0.138\n",
            "epoch   35 train acc 0.955 loss 0.136\n",
            "epoch   36 train acc 0.956 loss 0.134\n",
            "epoch   37 train acc 0.956 loss 0.133\n",
            "epoch   38 train acc 0.957 loss 0.131\n",
            "epoch   39 train acc 0.958 loss 0.129\n",
            "epoch   40 train acc 0.959 loss 0.127\n",
            "epoch   41 train acc 0.959 loss 0.125\n",
            "epoch   42 train acc 0.960 loss 0.123\n",
            "epoch   43 train acc 0.961 loss 0.122\n",
            "epoch   44 train acc 0.961 loss 0.120\n",
            "epoch   45 train acc 0.962 loss 0.118\n",
            "epoch   46 train acc 0.963 loss 0.117\n",
            "epoch   47 train acc 0.963 loss 0.115\n",
            "epoch   48 train acc 0.964 loss 0.114\n",
            "epoch   49 train acc 0.964 loss 0.112\n",
            "epoch   50 train acc 0.965 loss 0.111\n",
            "epoch   51 train acc 0.965 loss 0.109\n",
            "epoch   52 train acc 0.966 loss 0.108\n",
            "epoch   53 train acc 0.966 loss 0.107\n",
            "epoch   54 train acc 0.967 loss 0.105\n",
            "epoch   55 train acc 0.967 loss 0.104\n",
            "epoch   56 train acc 0.968 loss 0.103\n",
            "epoch   57 train acc 0.968 loss 0.101\n",
            "epoch   58 train acc 0.969 loss 0.100\n",
            "epoch   59 train acc 0.969 loss 0.099\n",
            "epoch   60 train acc 0.969 loss 0.098\n",
            "epoch   61 train acc 0.970 loss 0.097\n",
            "epoch   62 train acc 0.970 loss 0.096\n",
            "epoch   63 train acc 0.971 loss 0.095\n",
            "epoch   64 train acc 0.971 loss 0.094\n",
            "epoch   65 train acc 0.971 loss 0.093\n",
            "epoch   66 train acc 0.972 loss 0.092\n",
            "epoch   67 train acc 0.972 loss 0.091\n",
            "epoch   68 train acc 0.972 loss 0.090\n",
            "epoch   69 train acc 0.973 loss 0.089\n",
            "epoch   70 train acc 0.973 loss 0.088\n",
            "epoch   71 train acc 0.973 loss 0.087\n",
            "epoch   72 train acc 0.974 loss 0.086\n",
            "epoch   73 train acc 0.974 loss 0.085\n",
            "epoch   74 train acc 0.974 loss 0.084\n",
            "epoch   75 train acc 0.975 loss 0.083\n",
            "epoch   76 train acc 0.975 loss 0.083\n",
            "epoch   77 train acc 0.975 loss 0.082\n",
            "epoch   78 train acc 0.975 loss 0.081\n",
            "epoch   79 train acc 0.976 loss 0.080\n",
            "epoch   80 train acc 0.976 loss 0.079\n",
            "epoch   81 train acc 0.976 loss 0.079\n",
            "epoch   82 train acc 0.976 loss 0.078\n",
            "epoch   83 train acc 0.977 loss 0.077\n",
            "epoch   84 train acc 0.977 loss 0.076\n",
            "epoch   85 train acc 0.977 loss 0.076\n",
            "epoch   86 train acc 0.977 loss 0.075\n",
            "epoch   87 train acc 0.978 loss 0.074\n",
            "epoch   88 train acc 0.978 loss 0.074\n",
            "epoch   89 train acc 0.978 loss 0.073\n",
            "epoch   90 train acc 0.978 loss 0.072\n",
            "epoch   91 train acc 0.978 loss 0.072\n",
            "epoch   92 train acc 0.979 loss 0.071\n",
            "epoch   93 train acc 0.979 loss 0.071\n",
            "epoch   94 train acc 0.979 loss 0.070\n",
            "epoch   95 train acc 0.979 loss 0.069\n",
            "epoch   96 train acc 0.979 loss 0.069\n",
            "epoch   97 train acc 0.980 loss 0.068\n",
            "epoch   98 train acc 0.980 loss 0.068\n",
            "epoch   99 train acc 0.980 loss 0.067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzZWF0ns5Xk6",
        "outputId": "f86e16a6-fa60-4b28-b5c8-e843028344a2"
      },
      "source": [
        "# 마지막 회차까지 학습한 모델로 다음 회차 추론\n",
        "\n",
        "print('receive numbers')\n",
        "\n",
        "xs = x_samples[-1].reshape(1, 1, 45)\n",
        "\n",
        "ys_pred = model.predict_on_batch(xs)\n",
        "\n",
        "list_numbers = []\n",
        "\n",
        "for n in range(10):\n",
        "    numbers = gen_numbers_from_probability(ys_pred[0])\n",
        "    print('{0} : {1}'.format(n, numbers))\n",
        "    list_numbers.append(numbers)  "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "receive numbers\n",
            "0 : [44, 23, 11, 31, 6, 25]\n",
            "1 : [11, 23, 16, 44, 25, 6]\n",
            "2 : [23, 11, 44, 45, 7, 37]\n",
            "3 : [11, 45, 23, 44, 5, 40]\n",
            "4 : [11, 23, 25, 45, 44, 14]\n",
            "5 : [23, 11, 25, 45, 31, 44]\n",
            "6 : [11, 44, 25, 23, 24, 1]\n",
            "7 : [44, 45, 11, 25, 40, 5]\n",
            "8 : [44, 5, 45, 23, 37, 11]\n",
            "9 : [11, 23, 45, 40, 24, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPrVPjFF4xLP"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}
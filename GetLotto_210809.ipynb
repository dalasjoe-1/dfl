{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GetLotto.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Q8MptZ7cjH8T"
      ],
      "authorship_tag": "ABX9TyNVZQClIRZLTdAIKPJsOSMB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dalasjoe-1/dfl/blob/master/GetLotto_210809.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kCmxwN5Rkt1"
      },
      "source": [
        "# Another Way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl8KqROtQ5oG"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from os import path\n",
        "from google.colab import drive\n",
        "\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "tf.compat.v1.set_random_seed(777)\n",
        "\n",
        "input_data_column_cnt = 45  # 입력데이터의 컬럼 개수(Variable 개수)\n",
        "#output_data_column_cnt = 1  # 결과데이터의 컬럼 개수\n",
        "output_data_column_cnt = 45  # 결과데이터의 컬럼 개수\n",
        "\n",
        "seq_length = 46 #192 #24 #96  # 1개 시퀀스의 길이(시계열데이터 입력 개수)\n",
        "rnn_cell_hidden_dim = 20  # 각 셀의 (hidden)출력 크기\n",
        "forget_bias = 1.0  # 망각편향(기본값 1.0)\n",
        "num_stacked_layers = 1  # stacked LSTM layers 개수\n",
        "keep_prob = 1.0  # dropout할 때 keep할 비율\n",
        "\n",
        "epoch_num = 18000 #20000  # 에폭 횟수(학습용전체데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
        "learning_rate = 0.01  # 학습률\n",
        "\n",
        "# Standardization\n",
        "def data_standardization(x):\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np - x_np.mean()) / x_np.std()\n",
        "\n",
        "# 너무 작거나 너무 큰 값이 학습을 방해하는 것을 방지하고자 정규화한다\n",
        "# x가 양수라는 가정하에 최소값과 최대값을 이용하여 0~1사이의 값으로 변환\n",
        "# Min-Max scaling\n",
        "def min_max_scaling(x):\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np - x_np.min()) / (x_np.max() - x_np.min() + 1e-7)  # 1e-7은 0으로 나누는 오류 예방차원\n",
        "\n",
        "# 정규화된 값을 원래의 값으로 되돌린다\n",
        "# 정규화하기 이전의 org_x값과 되돌리고 싶은 x를 입력하면 역정규화된 값을 리턴한다\n",
        "def reverse_min_max_scaling(org_x, x):\n",
        "    org_x_np = np.asarray(org_x)\n",
        "    x_np = np.asarray(x)\n",
        "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()\n",
        "\n",
        "# data\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "#input = np.loadtxt('./gdrive/MyDrive/ori.data', unpack=True, dtype='int')\n",
        "input = np.loadtxt(\"./gdrive/MyDrive/lotto_data.txt\", delimiter=\",\", dtype='int')\n",
        "#data = np.transpose(input)\n",
        "data = input\n",
        "#win_numbers = data[:,1:data.size]\n",
        "win_numbers = data[:,1:7]\n",
        "\n",
        "#print(win_numbers, \" : \", win_numbers.size)\n",
        "norm_win_numbers = min_max_scaling(win_numbers)  # 가격형태 데이터 정규화 처리\n",
        "\n",
        "#x = min_max_scaling(win_numbers);\n",
        "x = win_numbers\n",
        "y = x[:, :]\n",
        "z = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "    week = win_numbers[i]  \n",
        "    buckets = [0, 0, 0, 0, 0, 0, 0,\n",
        "        0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,\n",
        "        0,0,0,0,0,0,0,\n",
        "        0,0,0]\n",
        "    for j in range(len(week)):\n",
        "        k = week[j]\n",
        "        buckets[k-1] = 100\n",
        "    z.append(buckets)\n",
        "\n",
        "x = z;\n",
        "y = x;\n",
        "\n",
        "dataX = []  # 입력으로 사용될 Sequence Data\n",
        "dataY = []  # 출력(타켓)으로 사용\n",
        "\n",
        "for i in range(0, len(y) - seq_length):\n",
        "    _x = x[i: i + seq_length]\n",
        "    _y = y[i + seq_length]  # 다음 나타날 주가(정답)\n",
        "    # if i is 0:\n",
        "    #      print(\">>> \", _x, \"->\", _y)  # 첫번째 행만 출력해 봄\n",
        "\n",
        "    dataX.append(_x)  # dataX 리스트에 추가\n",
        "    dataY.append(_y)  # dataY 리스트에 추가\n",
        "\n",
        "# 학습용/테스트용 데이터 생성\n",
        "# 전체 70%를 학습용 데이터로 사용\n",
        "train_size = int(len(dataY) * 0.7)\n",
        "# 나머지(30%)를 테스트용 데이터로 사용\n",
        "test_size = len(dataY) - train_size\n",
        "\n",
        "\n",
        "# 데이터를 잘라 학습용 데이터 생성\n",
        "trainX = np.asarray(dataX[0:train_size])\n",
        "trainY = np.asarray(dataY[0:train_size])\n",
        "\n",
        "# for i in range(len(trainX)):\n",
        "#     aaa = trainX[i]\n",
        "#     if (i==0):\n",
        "\n",
        "print(trainX.shape, \" ==== \", trainY.shape)\n",
        "# print(trainX[0], \" **** \", dataX[0])\n",
        "\n",
        "\n",
        "# 데이터를 잘라 테스트용 데이터 생성\n",
        "testX = np.array(dataX[train_size:len(dataX)])\n",
        "testY = np.array(dataY[train_size:len(dataY)])\n",
        "\n",
        "# 텐서플로우 플레이스홀더 생성\n",
        "# 입력 X, 출력 Y를 생성한다\n",
        "X = tf.compat.v1.placeholder(tf.float32, [None, seq_length, input_data_column_cnt])\n",
        "print(\"X: \", X)\n",
        "Y = tf.compat.v1.placeholder(tf.float32, [None, output_data_column_cnt])\n",
        "print(\"Y: \", Y)\n",
        "\n",
        "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성한다\n",
        "targets = tf.compat.v1.placeholder(tf.float32, [None, output_data_column_cnt])\n",
        "print(\"targets: \", targets)\n",
        "\n",
        "predictions = tf.compat.v1.placeholder(tf.float32, [None, output_data_column_cnt])\n",
        "print(\"predictions: \", predictions)\n",
        "\n",
        "def lstm_cell():\n",
        "    # LSTM셀을 생성\n",
        "    # num_units: 각 Cell 출력 크기\n",
        "    # forget_bias:  to the biases of the forget gate\n",
        "    #              (default: 1)  in order to reduce the scale of forgetting in the beginning of the training.\n",
        "    # state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\n",
        "    # state_is_tuple: False ==> they are concatenated along the column axis.\n",
        "\n",
        "    cell = tf.compat.v1.nn.rnn_cell.LSTMCell(num_units=rnn_cell_hidden_dim,\n",
        "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
        "   \n",
        "    # cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim,\n",
        "    #                                     forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
        "    #cell = tf.keras.layers.LSTMCell(num_units=rnn_cell_hidden_dim, forget_bias=forget_bias\n",
        "    #                                 , state_is_tuple=True, activation=tf.nn.softsign)\n",
        "    if keep_prob < 1.0:\n",
        "        #cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
        "        cell = tf.compat.v1.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
        "    return cell\n",
        "\n",
        "\n",
        "# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
        "stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
        "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()\n",
        "\n",
        "hypothesis, _states = tf.compat.v1.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
        "#hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
        "print(\"hypothesis: \", hypothesis)\n",
        "\n",
        "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
        "# 과거 여러 거래일의 주가를 이용해서 다음날의 주가 1개를 예측하기때문에 MANY-TO-ONE형태이다\n",
        "#hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)\n",
        "hypothesis = tf.compat.v1.layers.dense(hypothesis[:, -1], output_data_column_cnt, activation = tf.identity)\n",
        "\n",
        "\n",
        "\n",
        "# 손실함수로 평균제곱오차를 사용한다\n",
        "loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
        "# 최적화함수로 AdamOptimizer를 사용한다\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)\n",
        "# optimizer = tf.train.RMSPropOptimizer(learning_rate) # LSTM과 궁합 별로임\n",
        "\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "# RMSE(Root Mean Square Error)\n",
        "# 제곱오차의 평균을 구하고 다시 제곱근을 구하면 평균 오차가 나온다\n",
        "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets-predictions))) # 아래 코드와 같다\n",
        "rmse = tf.sqrt(tf.reduce_mean(tf.math.squared_difference(targets, predictions)))\n",
        "\n",
        "train_error_summary = []  # 학습용 데이터의 오류를 중간 중간 기록한다\n",
        "test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
        "test_predict = ''  # 테스트용데이터로 예측한 결과\n",
        "\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "print(\"trainX.shape=\", trainX.shape, \"trainY.shape=\", trainY.shape)\n",
        "print(\"trainX=\", trainX)\n",
        "\n",
        "# 학습한다\n",
        "start_time = datetime.datetime.now()  # 시작시간을 기록한다\n",
        "print('학습을 시작합니다...')\n",
        "for epoch in range(epoch_num):\n",
        "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
        "    if ((epoch + 1) % 100 == 0) or (epoch == epoch_num - 1):  # 100번째마다 또는 마지막 epoch인 경우\n",
        "        # 학습용데이터로 rmse오차를 구한다\n",
        "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
        "        train_error = sess.run(rmse, feed_dict={targets: trainY, predictions: train_predict})\n",
        "        train_error_summary.append(train_error)\n",
        "\n",
        "        # 테스트용데이터로 rmse오차를 구한다\n",
        "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
        "        test_error = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict})\n",
        "        test_error_summary.append(test_error)\n",
        "\n",
        "        # 현재 오류를 출력한다\n",
        "        print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch + 1, train_error, test_error,\n",
        "                                                                                 test_error - train_error))\n",
        "\n",
        "# end_time = datetime.datetime.now()  # 종료시간을 기록한다\n",
        "# elapsed_time = end_time - start_time  # 경과시간을 구한다\n",
        "# print('elapsed_time:', elapsed_time)\n",
        "# print('elapsed_time per epoch:', elapsed_time / epoch_num)\n",
        "#\n",
        "# # 하이퍼파라미터 출력\n",
        "# print('input_data_column_cnt:', input_data_column_cnt, end='')\n",
        "# print(',output_data_column_cnt:', output_data_column_cnt, end='')\n",
        "#\n",
        "# print(',seq_length:', seq_length, end='')\n",
        "# print(',rnn_cell_hidden_dim:', rnn_cell_hidden_dim, end='')\n",
        "# print(',forget_bias:', forget_bias, end='')\n",
        "# print(',num_stacked_layers:', num_stacked_layers, end='')\n",
        "# print(',keep_prob:', keep_prob, end='')\n",
        "#\n",
        "# print(',epoch_num:', epoch_num, end='')\n",
        "# print(',learning_rate:', learning_rate, end='')\n",
        "#\n",
        "# print(',train_error:', train_error_summary[-1], end='')\n",
        "# print(',test_error:', test_error_summary[-1], end='')\n",
        "# print(',min_test_error:', np.min(test_error_summary))\n",
        "#\n",
        "# # 결과 그래프 출력\n",
        "# plt.figure(1)\n",
        "# plt.plot(train_error_summary, 'gold')\n",
        "# plt.plot(test_error_summary, 'b')\n",
        "# plt.xlabel('Epoch(x100)')\n",
        "# plt.ylabel('Root Mean Square Error')\n",
        "#\n",
        "# plt.figure(2)\n",
        "# plt.plot(testY, 'r')\n",
        "# plt.plot(test_predict, 'b')\n",
        "# plt.xlabel('Time Period')\n",
        "# plt.ylabel('Stock Price')\n",
        "# plt.show()\n",
        "\n",
        "# sequence length만큼의 가장 최근 데이터를 슬라이싱한다\n",
        "recent_data = np.array([x[len(x) - seq_length:]])\n",
        "print(\"recent_data.shape:\", recent_data.shape)\n",
        "print(\"recent_data:\", recent_data)\n",
        "\n",
        "# 내일 종가를 예측해본다\n",
        "test_predict = sess.run(hypothesis, feed_dict={X: recent_data})\n",
        "\n",
        "test_predict_2 = []\n",
        "\n",
        "for i in range(len(test_predict[0])):\n",
        "    test_predict[0][i] = int(test_predict[0][i])\n",
        "    test_predict_2.append((test_predict[0][i], i))\n",
        "\n",
        "#final_predict = np.sort(test_predict_2, axis=1)[::-1]\n",
        "print(\"test_predict_2  00000 =\", test_predict_2)\n",
        "test_predict_2.sort(key = lambda element : element[0], reverse=True)\n",
        "\n",
        "\n",
        "# predict_six = []\n",
        "#\n",
        "# for i in final_predict:\n",
        "#     for j in test_predict[0]:\n",
        "#         if (final_predict[i] == test_predict[0][j])\n",
        "\n",
        "\n",
        "#print(\"test_predict 0 \", test_predict[0])\n",
        "print(\"test_predict_2  11111\", test_predict_2)\n",
        "\n",
        "picked = []\n",
        "for i in range(6):\n",
        "    picked.append(test_predict_2[i][1] + 1)\n",
        "\n",
        "print(picked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7T2b3Uw0n_u",
        "outputId": "ce55fe8f-e208-4fa5-fba8-d4b7a9d3891e"
      },
      "source": [
        "# 내일 종가를 예측해본다\n",
        "test_predict = sess.run(hypothesis, feed_dict={X: recent_data})\n",
        "\n",
        "test_predict_2 = []\n",
        "\n",
        "for i in range(len(test_predict[0])):\n",
        "    test_predict[0][i] = int(test_predict[0][i])\n",
        "    test_predict_2.append((test_predict[0][i], i))\n",
        "\n",
        "#final_predict = np.sort(test_predict_2, axis=1)[::-1]\n",
        "print(\"test_predict_2  00000 =\", test_predict_2)\n",
        "test_predict_2.sort(key = lambda element : element[0], reverse=True)\n",
        "\n",
        "\n",
        "# predict_six = []\n",
        "#\n",
        "# for i in final_predict:\n",
        "#     for j in test_predict[0]:\n",
        "#         if (final_predict[i] == test_predict[0][j])\n",
        "\n",
        "\n",
        "#print(\"test_predict 0 \", test_predict[0])\n",
        "print(\"test_predict_2  11111\", test_predict_2)\n",
        "\n",
        "picked = []\n",
        "for i in range(6):\n",
        "    picked.append(test_predict_2[i][1] + 1)\n",
        "\n",
        "print(picked)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_predict_2  00000 = [(-28.0, 0), (9.0, 1), (7.0, 2), (3.0, 3), (31.0, 4), (10.0, 5), (40.0, 6), (9.0, 7), (8.0, 8), (15.0, 9), (6.0, 10), (11.0, 11), (24.0, 12), (28.0, 13), (38.0, 14), (17.0, 15), (20.0, 16), (1.0, 17), (55.0, 18), (-1.0, 19), (-9.0, 20), (4.0, 21), (0.0, 22), (0.0, 23), (-4.0, 24), (39.0, 25), (-16.0, 26), (18.0, 27), (-2.0, 28), (20.0, 29), (23.0, 30), (4.0, 31), (-20.0, 32), (-2.0, 33), (0.0, 34), (24.0, 35), (34.0, 36), (35.0, 37), (-4.0, 38), (8.0, 39), (12.0, 40), (29.0, 41), (71.0, 42), (2.0, 43), (22.0, 44)]\n",
            "test_predict_2  11111 [(71.0, 42), (55.0, 18), (40.0, 6), (39.0, 25), (38.0, 14), (35.0, 37), (34.0, 36), (31.0, 4), (29.0, 41), (28.0, 13), (24.0, 12), (24.0, 35), (23.0, 30), (22.0, 44), (20.0, 16), (20.0, 29), (18.0, 27), (17.0, 15), (15.0, 9), (12.0, 40), (11.0, 11), (10.0, 5), (9.0, 1), (9.0, 7), (8.0, 8), (8.0, 39), (7.0, 2), (6.0, 10), (4.0, 21), (4.0, 31), (3.0, 3), (2.0, 43), (1.0, 17), (0.0, 22), (0.0, 23), (0.0, 34), (-1.0, 19), (-2.0, 28), (-2.0, 33), (-4.0, 24), (-4.0, 38), (-9.0, 20), (-16.0, 26), (-20.0, 32), (-28.0, 0)]\n",
            "[43, 19, 7, 26, 15, 38]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP2-bRVzoZ9T"
      },
      "source": [
        "# ALL Together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zzbFpN7ZokLu",
        "outputId": "a55753af-beab-428f-c48a-44b21f304e4d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from os import path\n",
        "from google.colab import drive\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "!pip install tensorflow-gpu==2.0.0-rc1\n",
        "\n",
        "main_url = \"https://www.dhlottery.co.kr/gameResult.do?method=byWin\" # 마지막 회차를 얻기 위한 주소\n",
        "basic_url = \"https://www.dhlottery.co.kr/gameResult.do?method=byWin&drwNo=\" # 임의의 회차를 얻기 위한 주소\n",
        "\n",
        "# 마지막 회차 정보를 가져옴\n",
        "def GetLast(): \n",
        "    resp = requests.get(main_url)\n",
        "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
        "    result = str(soup.find(\"meta\", {\"id\" : \"desc\", \"name\" : \"description\"})['content'])\n",
        "    s_idx = result.find(\" \")\n",
        "    e_idx = result.find(\"회\")\n",
        "    return int(result[s_idx + 1 : e_idx])\n",
        "\n",
        "# 지정된 파일에 지정된 범위의 회차 정보를 기록함\n",
        "def Crawler(s_count, e_count, fp):\n",
        "    for i in range(s_count , e_count + 1):\n",
        "        crawler_url = basic_url + str(i)\n",
        "        resp = requests.get(crawler_url)\n",
        "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "        text = soup.text\n",
        "\n",
        "        s_idx = text.find(\" 당첨결과\")\n",
        "        s_idx = text.find(\"당첨번호\", s_idx) + 4\n",
        "        e_idx = text.find(\"보너스\", s_idx)\n",
        "        numbers = text[s_idx:e_idx].strip().split()\n",
        "\n",
        "        s_idx = e_idx + 3\n",
        "        e_idx = s_idx + 3\n",
        "        bonus = text[s_idx:e_idx].strip()\n",
        "\n",
        "        s_idx = text.find(\"1등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money1 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"2등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money2 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"3등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money3 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"4등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money4 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"5등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money5 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        line = str(i) + ',' + numbers[0] + ',' + numbers[1] + ',' + numbers[2] + ',' + numbers[3] + ',' + numbers[4] + ',' + numbers[5] + ',' + bonus + ',' + money1 + ',' + money2 + ',' + money3 + ',' + money4 + ',' + money5\n",
        "        print(line)\n",
        "        line += '\\n'\n",
        "        fp.write(line)\n",
        "\n",
        "last = GetLast() # 마지막 회차를 가져옴\n",
        "\n",
        "lotto_dir_name='lotto'\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "lotto_base_dir=path.join('./gdrive/My Drive/', '')\n",
        "if not path.exists(lotto_base_dir):\n",
        "  print('Check your google drive directory. See you file explorer')\n",
        "\n",
        "\n",
        "print (\"Last=\",last)\n",
        "\n",
        "# 완전히 다시 쓰기\n",
        "#fp = open(path.join(lotto_base_dir, \"lotto_data.txt\"), 'w')\n",
        "\n",
        "# 기존 데이타에 추가하기\n",
        "fp = open(path.join(lotto_base_dir, \"lotto_data.txt\"), 'a')\n",
        "Crawler(last-1, last, fp) # 처음부터 마지막 회차까지 저장\n",
        "fp.close()\n",
        "\n",
        "#  --------------\n",
        "#  번호 저장 끝\n",
        "#  -------------\n",
        "\n",
        "# 당첨번호를 원핫인코딩벡터(ohbin)으로 변환\n",
        "def numbers2ohbin(numbers):\n",
        "\n",
        "    ohbin = np.zeros(45) #45개의 빈 칸을 만듬\n",
        "\n",
        "    for i in range(6): #여섯개의 당첨번호에 대해서 반복함\n",
        "        ohbin[int(numbers[i])-1] = 1 #로또번호가 1부터 시작하지만 벡터의 인덱스 시작은 0부터 시작하므로 1을 뺌\n",
        "    \n",
        "    return ohbin\n",
        "\n",
        "# 원핫인코딩벡터(ohbin)를 번호로 변환\n",
        "def ohbin2numbers(ohbin):\n",
        "\n",
        "    numbers = []\n",
        "    \n",
        "    for i in range(len(ohbin)):\n",
        "        if ohbin[i] == 1.0: # 1.0으로 설정되어 있으면 해당 번호를 반환값에 추가한다.\n",
        "            numbers.append(i+1)\n",
        "    \n",
        "    return numbers\n",
        "\n",
        "\n",
        "rows = np.loadtxt(\"./gdrive/MyDrive/lotto_data.txt\", delimiter=\",\")\n",
        "row_count = len(rows)\n",
        "\n",
        "numbers = rows[:, 1:7]\n",
        "ohbins = list(map(numbers2ohbin, numbers))\n",
        "\n",
        "x_samples = ohbins[0:row_count-1]\n",
        "y_samples = ohbins[1:row_count]\n",
        "\n",
        "model = tf.keras.models.load_model('./gdrive/MyDrive/my_model.h5')\n",
        "model.summary()\n",
        "\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "\n",
        "# 88회부터 지금까지 1등부터 5등까지 상금의 평균낸다.\n",
        "mean_prize = [  np.mean(rows[87:, 8]),\n",
        "            np.mean(rows[87:, 9]),\n",
        "            np.mean(rows[87:, 10]),\n",
        "            np.mean(rows[87:, 11]),\n",
        "            np.mean(rows[87:, 12])]\n",
        "\n",
        "train_total_reward = []\n",
        "train_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "val_total_reward = []\n",
        "val_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "test_total_reward = []\n",
        "test_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "\n",
        "\n",
        "def gen_numbers_from_probability(nums_prob):\n",
        "\n",
        "    ball_box = []\n",
        "\n",
        "    for n in range(45):\n",
        "        ball_count = int(nums_prob[n] * 300 + 1)\n",
        "        ball = np.full((ball_count), n+1) #1부터 시작\n",
        "        ball_box += list(ball)\n",
        "\n",
        "    selected_balls = []\n",
        "\n",
        "    while True:\n",
        "        \n",
        "        if len(selected_balls) == 6:\n",
        "            break\n",
        "        \n",
        "        ball_index = np.random.randint(len(ball_box), size=1)[0]\n",
        "        ball = ball_box[ball_index]\n",
        "\n",
        "        if ball not in selected_balls:\n",
        "            selected_balls.append(ball)\n",
        "\n",
        "   \n",
        "    selected_balls.sort()\n",
        "\n",
        "    return selected_balls\n",
        "\n",
        "print('receive numbers')\n",
        "\n",
        "xs = x_samples[-1].reshape(1, 1, 45)\n",
        "\n",
        "ys_pred = model.predict_on_batch(xs)\n",
        "\n",
        "list_numbers = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 최대 100번 에포크까지 수행\n",
        "for epoch in range(50):\n",
        "\n",
        "    model.reset_states() # 중요! 매 에포크마다 1회부터 다시 훈련하므로 상태 초기화 필요\n",
        "\n",
        "    batch_train_loss = []\n",
        "    batch_train_acc = []\n",
        "\n",
        "    for i in range(len(x_samples)):\n",
        "        \n",
        "        xs = x_samples[i].reshape(1, 1, 45)\n",
        "        ys = y_samples[i].reshape(1, 45)\n",
        "        \n",
        "        loss, acc = model.train_on_batch(xs, ys) #배치만큼 모델에 학습시킴\n",
        "\n",
        "        batch_train_loss.append(loss)\n",
        "        batch_train_acc.append(acc)\n",
        "\n",
        "    train_loss.append(np.mean(batch_train_loss))\n",
        "    train_acc.append(np.mean(batch_train_acc))\n",
        "\n",
        "    print('epoch {0:4d} train acc {1:0.3f} loss {2:0.3f}'.format(epoch, np.mean(batch_train_acc), np.mean(batch_train_loss)))  \n",
        "\n",
        "\n",
        "# Trainning 끝나면 무조건 모델에 저장\n",
        "model.save('my_model.h5')\n",
        "!cp /content/my_model.h5 /content/drive/My\\ Drive/\n",
        "\n",
        "\n",
        "# 마지막 회차까지 학습한 모델로 다음 회차 추론\n",
        "\n",
        "# 50 개 뽑기\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "lotto_base_dir=path.join('./gdrive/My Drive/', '')\n",
        "with open(path.join(lotto_base_dir, \"predict2.txt\"), \"w\") as f:\n",
        "  print (\"predict.txt\")\n",
        "\n",
        "  for n in range(50):\n",
        "    numbers = gen_numbers_from_probability(ys_pred[0])  \n",
        "    print('{0} : {1}'.format(n, numbers))    \n",
        "    list_numbers.append(numbers)  \n",
        "    line_str=','.join(str(e) for e in numbers)\n",
        "    line_str += '\\n'\n",
        "    print(line_str)\n",
        "    f.write(line_str)\n",
        "f.close()\n",
        "\n",
        "from ftplib import FTP\n",
        "\n",
        "ftp = FTP('112.175.184.78')\n",
        "ftp.login('dalasjoe', 'Dalasjoe75!')\n",
        "\n",
        "# ftp.cwd('html') # \"test\"디렉터리로 이동\n",
        "# ftp.retrlines('LIST') # 디렉터리의 내용을 목록화\n",
        "# #ftp.retrbinary('RETR README', open('README', 'wb').write) # README 파일 저장\n",
        "# ftp.quit()\n",
        "\n",
        "\n",
        "ftp.cwd('html')  # 업로드할 FTP 폴더로 이동\n",
        "myfile = open(path.join(lotto_base_dir, \"predict2.txt\"),'rb')  # 로컬 파일 열기\n",
        "ftp.storbinary('STOR ' + 'predict2.txt', myfile )  # 파일을 FTP로 업로드\n",
        "myfile.close()  # 파일 닫기\n",
        "\n",
        "print (\"File Saved\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-rc1\n",
            "  Downloading tensorflow_gpu-2.0.0rc1-cp37-cp37m-manylinux2010_x86_64.whl (380.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5 MB 10 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.39.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.17.3)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n",
            "  Downloading tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501 kB)\n",
            "\u001b[K     |████████████████████████████████| 501 kB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.19.5)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n",
            "  Downloading tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 32.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (4.6.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.7.4.3)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, keras-applications, tensorflow-gpu\n",
            "Successfully installed keras-applications-1.0.8 tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Last= 980\n",
            "979,7,11,16,21,27,33,24,1606400518,47446429,1097911,50000,5000\n",
            "980,3,13,16,23,24,35,14,3409443215,56824054,1411027,50000,5000\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (1, 128)                  89088     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (1, 45)                   5805      \n",
            "=================================================================\n",
            "Total params: 94,893\n",
            "Trainable params: 94,893\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "receive numbers\n",
            "epoch    0 train acc 0.171 loss 0.048\n",
            "epoch    1 train acc 0.182 loss 0.048\n",
            "epoch    2 train acc 0.195 loss 0.030\n",
            "epoch    3 train acc 0.171 loss 0.025\n",
            "epoch    4 train acc 0.192 loss 0.020\n",
            "epoch    5 train acc 0.204 loss 0.017\n",
            "epoch    6 train acc 0.172 loss 0.018\n",
            "epoch    7 train acc 0.160 loss 0.018\n",
            "epoch    8 train acc 0.195 loss 0.015\n",
            "epoch    9 train acc 0.180 loss 0.018\n",
            "epoch   10 train acc 0.166 loss 0.015\n",
            "epoch   11 train acc 0.157 loss 0.015\n",
            "epoch   12 train acc 0.151 loss 0.014\n",
            "epoch   13 train acc 0.175 loss 0.015\n",
            "epoch   14 train acc 0.186 loss 0.014\n",
            "epoch   15 train acc 0.173 loss 0.013\n",
            "epoch   16 train acc 0.181 loss 0.013\n",
            "epoch   17 train acc 0.168 loss 0.011\n",
            "epoch   18 train acc 0.188 loss 0.011\n",
            "epoch   19 train acc 0.170 loss 0.011\n",
            "epoch   20 train acc 0.182 loss 0.011\n",
            "epoch   21 train acc 0.184 loss 0.015\n",
            "epoch   22 train acc 0.184 loss 0.012\n",
            "epoch   23 train acc 0.174 loss 0.010\n",
            "epoch   24 train acc 0.170 loss 0.009\n",
            "epoch   25 train acc 0.166 loss 0.015\n",
            "epoch   26 train acc 0.163 loss 0.011\n",
            "epoch   27 train acc 0.173 loss 0.009\n",
            "epoch   28 train acc 0.161 loss 0.013\n",
            "epoch   29 train acc 0.186 loss 0.012\n",
            "epoch   30 train acc 0.192 loss 0.009\n",
            "epoch   31 train acc 0.192 loss 0.008\n",
            "epoch   32 train acc 0.195 loss 0.009\n",
            "epoch   33 train acc 0.160 loss 0.013\n",
            "epoch   34 train acc 0.170 loss 0.011\n",
            "epoch   35 train acc 0.157 loss 0.010\n",
            "epoch   36 train acc 0.176 loss 0.008\n",
            "epoch   37 train acc 0.177 loss 0.008\n",
            "epoch   38 train acc 0.204 loss 0.007\n",
            "epoch   39 train acc 0.182 loss 0.010\n",
            "epoch   40 train acc 0.177 loss 0.012\n",
            "epoch   41 train acc 0.194 loss 0.013\n",
            "epoch   42 train acc 0.197 loss 0.008\n",
            "epoch   43 train acc 0.183 loss 0.007\n",
            "epoch   44 train acc 0.169 loss 0.009\n",
            "epoch   45 train acc 0.170 loss 0.013\n",
            "epoch   46 train acc 0.171 loss 0.010\n",
            "epoch   47 train acc 0.177 loss 0.008\n",
            "epoch   48 train acc 0.168 loss 0.008\n",
            "epoch   49 train acc 0.177 loss 0.007\n",
            "cp: cannot create regular file '/content/drive/My Drive/': No such file or directory\n",
            "Mounted at /content/gdrive\n",
            "predict.txt\n",
            "0 : [13, 14, 15, 21, 25, 40]\n",
            "13,14,15,21,25,40\n",
            "\n",
            "1 : [9, 13, 15, 21, 25, 42]\n",
            "9,13,15,21,25,42\n",
            "\n",
            "2 : [3, 9, 15, 21, 30, 42]\n",
            "3,9,15,21,30,42\n",
            "\n",
            "3 : [2, 9, 13, 14, 25, 34]\n",
            "2,9,13,14,25,34\n",
            "\n",
            "4 : [3, 13, 14, 21, 25, 40]\n",
            "3,13,14,21,25,40\n",
            "\n",
            "5 : [15, 16, 21, 25, 38, 42]\n",
            "15,16,21,25,38,42\n",
            "\n",
            "6 : [9, 15, 21, 34, 38, 42]\n",
            "9,15,21,34,38,42\n",
            "\n",
            "7 : [2, 9, 13, 15, 21, 30]\n",
            "2,9,13,15,21,30\n",
            "\n",
            "8 : [8, 13, 15, 30, 42, 45]\n",
            "8,13,15,30,42,45\n",
            "\n",
            "9 : [9, 13, 14, 30, 38, 42]\n",
            "9,13,14,30,38,42\n",
            "\n",
            "10 : [9, 10, 13, 21, 30, 40]\n",
            "9,10,13,21,30,40\n",
            "\n",
            "11 : [9, 13, 15, 21, 25, 42]\n",
            "9,13,15,21,25,42\n",
            "\n",
            "12 : [9, 15, 25, 30, 35, 40]\n",
            "9,15,25,30,35,40\n",
            "\n",
            "13 : [2, 3, 9, 13, 25, 42]\n",
            "2,3,9,13,25,42\n",
            "\n",
            "14 : [3, 9, 14, 15, 21, 42]\n",
            "3,9,14,15,21,42\n",
            "\n",
            "15 : [9, 21, 25, 30, 42, 43]\n",
            "9,21,25,30,42,43\n",
            "\n",
            "16 : [1, 9, 21, 30, 38, 42]\n",
            "1,9,21,30,38,42\n",
            "\n",
            "17 : [9, 13, 21, 25, 30, 42]\n",
            "9,13,21,25,30,42\n",
            "\n",
            "18 : [3, 9, 14, 21, 30, 42]\n",
            "3,9,14,21,30,42\n",
            "\n",
            "19 : [9, 13, 15, 21, 40, 42]\n",
            "9,13,15,21,40,42\n",
            "\n",
            "20 : [9, 13, 14, 15, 25, 30]\n",
            "9,13,14,15,25,30\n",
            "\n",
            "21 : [9, 13, 15, 21, 25, 30]\n",
            "9,13,15,21,25,30\n",
            "\n",
            "22 : [3, 9, 15, 21, 30, 43]\n",
            "3,9,15,21,30,43\n",
            "\n",
            "23 : [1, 2, 9, 10, 13, 15]\n",
            "1,2,9,10,13,15\n",
            "\n",
            "24 : [13, 15, 25, 30, 33, 42]\n",
            "13,15,25,30,33,42\n",
            "\n",
            "25 : [9, 13, 14, 17, 35, 43]\n",
            "9,13,14,17,35,43\n",
            "\n",
            "26 : [3, 15, 21, 25, 38, 42]\n",
            "3,15,21,25,38,42\n",
            "\n",
            "27 : [9, 15, 21, 25, 38, 42]\n",
            "9,15,21,25,38,42\n",
            "\n",
            "28 : [2, 6, 13, 14, 15, 42]\n",
            "2,6,13,14,15,42\n",
            "\n",
            "29 : [13, 15, 21, 25, 38, 42]\n",
            "13,15,21,25,38,42\n",
            "\n",
            "30 : [2, 9, 14, 25, 38, 42]\n",
            "2,9,14,25,38,42\n",
            "\n",
            "31 : [3, 9, 13, 14, 15, 42]\n",
            "3,9,13,14,15,42\n",
            "\n",
            "32 : [2, 9, 13, 14, 40, 42]\n",
            "2,9,13,14,40,42\n",
            "\n",
            "33 : [3, 13, 15, 25, 30, 42]\n",
            "3,13,15,25,30,42\n",
            "\n",
            "34 : [8, 9, 13, 15, 32, 43]\n",
            "8,9,13,15,32,43\n",
            "\n",
            "35 : [9, 13, 14, 25, 30, 42]\n",
            "9,13,14,25,30,42\n",
            "\n",
            "36 : [3, 9, 21, 27, 30, 42]\n",
            "3,9,21,27,30,42\n",
            "\n",
            "37 : [2, 3, 9, 21, 28, 42]\n",
            "2,3,9,21,28,42\n",
            "\n",
            "38 : [2, 9, 15, 25, 34, 40]\n",
            "2,9,15,25,34,40\n",
            "\n",
            "39 : [9, 14, 15, 25, 30, 42]\n",
            "9,14,15,25,30,42\n",
            "\n",
            "40 : [2, 3, 9, 13, 30, 42]\n",
            "2,3,9,13,30,42\n",
            "\n",
            "41 : [9, 13, 21, 25, 42, 43]\n",
            "9,13,21,25,42,43\n",
            "\n",
            "42 : [2, 3, 9, 13, 15, 25]\n",
            "2,3,9,13,15,25\n",
            "\n",
            "43 : [9, 13, 30, 34, 38, 42]\n",
            "9,13,30,34,38,42\n",
            "\n",
            "44 : [3, 13, 15, 16, 30, 40]\n",
            "3,13,15,16,30,40\n",
            "\n",
            "45 : [2, 7, 9, 15, 21, 42]\n",
            "2,7,9,15,21,42\n",
            "\n",
            "46 : [3, 9, 13, 15, 21, 40]\n",
            "3,9,13,15,21,40\n",
            "\n",
            "47 : [9, 13, 14, 15, 29, 38]\n",
            "9,13,14,15,29,38\n",
            "\n",
            "48 : [1, 9, 13, 14, 25, 42]\n",
            "1,9,13,14,25,42\n",
            "\n",
            "49 : [9, 13, 15, 21, 34, 42]\n",
            "9,13,15,21,34,42\n",
            "\n",
            "File Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSm4U5BjfO1R"
      },
      "source": [
        "# 저장된 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MABE44rDfTf8"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from os import path\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "otto_dir_name='lotto'\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "\n",
        "if not path.exists(lotto_base_dir):\n",
        "  print('Check your google drive directory. See you file explorer')\n",
        "\n",
        "lotto_base_dir=path.join('./gdrive/My Drive/', '')\n",
        "with open(path.join(lotto_base_dir, \"lotto_data.txt\"), \"r\") as f:\n",
        "  print(\"11111\")\n",
        "  line = f.read()\n",
        "  print(\">>>\" + line)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZRsvoibHt5d"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8MptZ7cjH8T"
      },
      "source": [
        "# **데이터 수집**  - Crawling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6kMeQ2_aCfm"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from os import path\n",
        "from google.colab import drive\n",
        "\n",
        "main_url = \"https://www.dhlottery.co.kr/gameResult.do?method=byWin\" # 마지막 회차를 얻기 위한 주소\n",
        "basic_url = \"https://www.dhlottery.co.kr/gameResult.do?method=byWin&drwNo=\" # 임의의 회차를 얻기 위한 주소\n",
        "\n",
        "# 마지막 회차 정보를 가져옴\n",
        "def GetLast(): \n",
        "    resp = requests.get(main_url)\n",
        "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
        "    result = str(soup.find(\"meta\", {\"id\" : \"desc\", \"name\" : \"description\"})['content'])\n",
        "    s_idx = result.find(\" \")\n",
        "    e_idx = result.find(\"회\")\n",
        "    return int(result[s_idx + 1 : e_idx])\n",
        "\n",
        "# 지정된 파일에 지정된 범위의 회차 정보를 기록함\n",
        "def Crawler(s_count, e_count, fp):\n",
        "    for i in range(s_count , e_count + 1):\n",
        "        crawler_url = basic_url + str(i)\n",
        "        resp = requests.get(crawler_url)\n",
        "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "        text = soup.text\n",
        "\n",
        "        s_idx = text.find(\" 당첨결과\")\n",
        "        s_idx = text.find(\"당첨번호\", s_idx) + 4\n",
        "        e_idx = text.find(\"보너스\", s_idx)\n",
        "        numbers = text[s_idx:e_idx].strip().split()\n",
        "\n",
        "        s_idx = e_idx + 3\n",
        "        e_idx = s_idx + 3\n",
        "        bonus = text[s_idx:e_idx].strip()\n",
        "\n",
        "        s_idx = text.find(\"1등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money1 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"2등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money2 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"3등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money3 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"4등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money4 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        s_idx = text.find(\"5등\", e_idx) + 2\n",
        "        e_idx = text.find(\"원\", s_idx) + 1\n",
        "        e_idx = text.find(\"원\", e_idx)\n",
        "        money5 = text[s_idx:e_idx].strip().replace(',','').split()[2]\n",
        "\n",
        "        line = str(i) + ',' + numbers[0] + ',' + numbers[1] + ',' + numbers[2] + ',' + numbers[3] + ',' + numbers[4] + ',' + numbers[5] + ',' + bonus + ',' + money1 + ',' + money2 + ',' + money3 + ',' + money4 + ',' + money5\n",
        "        print(line)\n",
        "        line += '\\n'\n",
        "        fp.write(line)\n",
        "\n",
        "last = GetLast() # 마지막 회차를 가져옴\n",
        "\n",
        "lotto_dir_name='lotto'\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "lotto_base_dir=path.join('./gdrive/My Drive/', '')\n",
        "if not path.exists(lotto_base_dir):\n",
        "  print('Check your google drive directory. See you file explorer')\n",
        "\n",
        "#with open(path.join(lotto_base_dir, \"lotto_data.txt\"), \"r\") as f:\n",
        "#  print(\"11111\")\n",
        "#   line = f.read()\n",
        "#   print(\">>>\" + line)\n",
        "\n",
        "print (\"Last=\",last)\n",
        "\n",
        "# 완전히 다시 쓰기\n",
        "#fp = open(path.join(lotto_base_dir, \"lotto_data.txt\"), 'w')\n",
        "\n",
        "# 기존 데이타에 추가하기\n",
        "fp = open(path.join(lotto_base_dir, \"lotto_data.txt\"), 'a')\n",
        "\n",
        "Crawler(1, last, fp) # 처음부터 마지막 회차까지 저장\n",
        "fp.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b59-XaqSHwpT"
      },
      "source": [
        "## 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGhgk1uAH1KF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8244175-9b54-4adc-a5ed-2d08cac781fd"
      },
      "source": [
        "from os import path\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "rows = np.loadtxt(\"./drive/MyDrive/lotto_data.txt\", delimiter=\",\")\n",
        "row_count = len(rows)\n",
        "\n",
        "print(\"Data Loaded : row count: \" + str(row_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Data Loaded : row count: 965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjyyBnKlfNfS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ0yqd9Xjmwh"
      },
      "source": [
        "# **TensorFlow 설치 및 모델 초기화**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-vuJrQn2pNt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "!pip install tensorflow-gpu==2.0.0-rc1\n",
        "\n",
        "# 당첨번호를 원핫인코딩벡터(ohbin)으로 변환\n",
        "def numbers2ohbin(numbers):\n",
        "\n",
        "    ohbin = np.zeros(45) #45개의 빈 칸을 만듬\n",
        "\n",
        "    for i in range(6): #여섯개의 당첨번호에 대해서 반복함\n",
        "        ohbin[int(numbers[i])-1] = 1 #로또번호가 1부터 시작하지만 벡터의 인덱스 시작은 0부터 시작하므로 1을 뺌\n",
        "    \n",
        "    return ohbin\n",
        "\n",
        "# 원핫인코딩벡터(ohbin)를 번호로 변환\n",
        "def ohbin2numbers(ohbin):\n",
        "\n",
        "    numbers = []\n",
        "    \n",
        "    for i in range(len(ohbin)):\n",
        "        if ohbin[i] == 1.0: # 1.0으로 설정되어 있으면 해당 번호를 반환값에 추가한다.\n",
        "            numbers.append(i+1)\n",
        "    \n",
        "    return numbers\n",
        "\n",
        "\n",
        "numbers = rows[:, 1:7]\n",
        "ohbins = list(map(numbers2ohbin, numbers))\n",
        "\n",
        "x_samples = ohbins[0:row_count-1]\n",
        "y_samples = ohbins[1:row_count]\n",
        "\n",
        "#원핫인코딩으로 표시\n",
        "print(\"ohbins\")\n",
        "print(\"X[0]: \" + str(x_samples[0]))\n",
        "print(\"Y[0]: \" + str(y_samples[0]))\n",
        "\n",
        "#번호로 표시\n",
        "print(\"numbers\")\n",
        "print(\"X[0]: \" + str(ohbin2numbers(x_samples[0])))\n",
        "print(\"Y[0]: \" + str(ohbin2numbers(y_samples[0])))\n",
        "\n",
        "# 데이터셋 구성\n",
        "train_idx = (0, 700) # 훈련셋 \n",
        "val_idx = (700, 800) # 검증셋\n",
        "test_idx = (800, len(x_samples)) #시험셋\n",
        "\n",
        "print(\"train: {0}, val: {1}, test: {2}\".format(train_idx, val_idx, test_idx))\n",
        "\n",
        "# 모델을 정의합니다. - LSTM\n",
        "#타입스텝은 1인 대신, 상태유지(stateful 옵션을 True)으로 설정했습니다.\n",
        "#45개의 벡터로 출력합니다.\n",
        "#각각의 벡터는 0.0과 1.0사이의 실수값으로 나옵니다. 각 벡터가 독립적으로 모두 1.0이 나오거나 0.0이 나올 수 있는 멀티레이블 문제입니다.\n",
        "#멀티레이블 문제라 출력층의 활성화함수가 softmax가 아닌 sigmoid로 설정하였습니다.\n",
        "model = keras.Sequential([\n",
        "    keras.layers.LSTM(128, batch_input_shape=(1, 1, 45), return_sequences=False, stateful=True),\n",
        "    keras.layers.Dense(45, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 모델을 컴파일합니다.\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 매 에포크마다 훈련과 검증의 손실 및 정확도를 기록하기 위한 변수\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "\n",
        "# 88회부터 지금까지 1등부터 5등까지 상금의 평균낸다.\n",
        "mean_prize = [  np.mean(rows[87:, 8]),\n",
        "            np.mean(rows[87:, 9]),\n",
        "            np.mean(rows[87:, 10]),\n",
        "            np.mean(rows[87:, 11]),\n",
        "            np.mean(rows[87:, 12])]\n",
        "\n",
        "print(mean_prize)   \n",
        "\n",
        "train_total_reward = []\n",
        "train_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "val_total_reward = []\n",
        "val_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "test_total_reward = []\n",
        "test_total_grade = np.zeros(6, dtype=int)\n",
        "\n",
        "model.reset_states()\n",
        "\n",
        "# print('[No. ] 1st 2nd 3rd 4th 5th 6th Rewards')\n",
        "\n",
        "# for i in range(len(x_samples)):\n",
        "#     xs = x_samples[i].reshape(1, 1, 45)\n",
        "#     ys_pred = model.predict_on_batch(xs) # 모델의 출력값을 얻음\n",
        "    \n",
        "#     sum_reward = 0\n",
        "#     sum_grade = np.zeros(6, dtype=int) # 6등까지 변수\n",
        "\n",
        "#     for n in range(10): # 10판 수행\n",
        "#         numbers = gen_numbers_from_probability(ys_pred[0])\n",
        "        \n",
        "#         #i회차 입력 후 나온 출력을 i+1회차와 비교함\n",
        "#         grade, reward = calc_reward(rows[i+1,1:7], rows[i+1,7], numbers) \n",
        "\n",
        "#         sum_reward += reward\n",
        "#         sum_grade[grade] += 1\n",
        "\n",
        "#         if i >= train_idx[0] and i < train_idx[1]:\n",
        "#             train_total_grade[grade] += 1\n",
        "#         elif i >= val_idx[0] and i < val_idx[1]:\n",
        "#             val_total_grade[grade] += 1\n",
        "#         elif i >= test_idx[0] and i < test_idx[1]:\n",
        "#             val_total_grade[grade] += 1\n",
        "    \n",
        "#     if i >= train_idx[0] and i < train_idx[1]:\n",
        "#         train_total_reward.append(sum_reward)\n",
        "#     elif i >= val_idx[0] and i < val_idx[1]:\n",
        "#         val_total_reward.append(sum_reward)\n",
        "#     elif i >= test_idx[0] and i < test_idx[1]:\n",
        "#         test_total_reward.append(sum_reward)\n",
        "                        \n",
        "#     print('[{0:4d}] {1:3d} {2:3d} {3:3d} {4:3d} {5:3d} {6:3d} {7:15,d}'.format(i+1, sum_grade[0], sum_grade[1], sum_grade[2], sum_grade[3], sum_grade[4], sum_grade[5], int(sum_reward)))\n",
        "\n",
        "# print('Total') \n",
        "# print('==========')    \n",
        "# print('Train {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(train_total_grade[0], train_total_grade[1], train_total_grade[2], train_total_grade[3], train_total_grade[4], train_total_grade[5], int(sum(train_total_reward))))\n",
        "# print('Val   {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(val_total_grade[0], val_total_grade[1], val_total_grade[2], val_total_grade[3], val_total_grade[4], val_total_grade[5], int(sum(val_total_reward))))\n",
        "# print('Test  {0:5d} {1:5d} {2:5d} {3:5d} {4:5d} {5:5d} {6:15,d}'.format(test_total_grade[0], test_total_grade[1], test_total_grade[2], test_total_grade[3], test_total_grade[4], test_total_grade[5], int(sum(test_total_reward))))\n",
        "# print('==========')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jigZv6GgC35S"
      },
      "source": [
        "model = tf.keras.models.load_model('./drive/MyDrive/my_model.h5')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S6KaOT3lyq5"
      },
      "source": [
        "# **Trainning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyJvMPVl5QV8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "1a70fd96-2cbd-4d8b-aebf-0d016f103efc"
      },
      "source": [
        "# 최대 100번 에포크까지 수행\n",
        "\n",
        "# function ClickConnect(){\n",
        "#     console.log(\"코랩 연결 끊김 방지\"); \n",
        "#     document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "# }\n",
        "# setInterval(ClickConnect, 60 * 1000)\n",
        "\n",
        "model = tf.keras.models.load_model('./drive/MyDrive/my_model.h5')\n",
        "model.summary()\n",
        "\n",
        "for epoch in range(50):\n",
        "\n",
        "    model.reset_states() # 중요! 매 에포크마다 1회부터 다시 훈련하므로 상태 초기화 필요\n",
        "\n",
        "    batch_train_loss = []\n",
        "    batch_train_acc = []\n",
        "\n",
        "    for i in range(len(x_samples)):\n",
        "        \n",
        "        xs = x_samples[i].reshape(1, 1, 45)\n",
        "        ys = y_samples[i].reshape(1, 45)\n",
        "        \n",
        "        loss, acc = model.train_on_batch(xs, ys) #배치만큼 모델에 학습시킴\n",
        "\n",
        "        batch_train_loss.append(loss)\n",
        "        batch_train_acc.append(acc)\n",
        "\n",
        "    train_loss.append(np.mean(batch_train_loss))\n",
        "    train_acc.append(np.mean(batch_train_acc))\n",
        "\n",
        "    print('epoch {0:4d} train acc {1:0.3f} loss {2:0.3f}'.format(epoch, np.mean(batch_train_acc), np.mean(batch_train_loss)))  \n",
        "\n",
        "\n",
        "# Trainning 끝나면 무조건 모델에 저장\n",
        "model.save('my_model.h5')\n",
        "!cp /content/my_model.h5 /content/drive/My\\ Drive/\n",
        "\n",
        "# 마지막 회차까지 학습한 모델로 다음 회차 추론\n",
        "\n",
        " # 등수와 상금을 반환함\n",
        "# 순위에 오르지 못한 경우에는 등수가 0으로 반환함\n",
        "def calc_reward(true_numbers, true_bonus, pred_numbers):\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for ps in pred_numbers:\n",
        "        if ps in true_numbers:\n",
        "            count += 1\n",
        "\n",
        "    if count == 6:\n",
        "        return 0, mean_prize[0]\n",
        "    elif count == 5 and true_bonus in pred_numbers:\n",
        "        return 1, mean_prize[1]\n",
        "    elif count == 5:\n",
        "        return 2, mean_prize[2]\n",
        "    elif count == 4:\n",
        "        return 3, mean_prize[3]\n",
        "    elif count == 3:\n",
        "        return 4, mean_prize[4]\n",
        "\n",
        "    return 5, 0\n",
        "\n",
        "def gen_numbers_from_probability(nums_prob):\n",
        "\n",
        "    ball_box = []\n",
        "\n",
        "    for n in range(45):\n",
        "        ball_count = int(nums_prob[n] * 100 + 1)\n",
        "        ball = np.full((ball_count), n+1) #1부터 시작\n",
        "        ball_box += list(ball)\n",
        "\n",
        "    selected_balls = []\n",
        "\n",
        "    while True:\n",
        "        \n",
        "        if len(selected_balls) == 6:\n",
        "            break\n",
        "        \n",
        "        ball_index = np.random.randint(len(ball_box), size=1)[0]\n",
        "        ball = ball_box[ball_index]\n",
        "\n",
        "        if ball not in selected_balls:\n",
        "            selected_balls.append(ball)\n",
        "\n",
        "   \n",
        "    selected_balls.sort()\n",
        "\n",
        "    return selected_balls\n",
        "\n",
        "print('receive numbers')\n",
        "\n",
        "xs = x_samples[-1].reshape(1, 1, 45)\n",
        "\n",
        "ys_pred = model.predict_on_batch(xs)\n",
        "\n",
        "list_numbers = []\n",
        "\n",
        "# 50 개 뽑기\n",
        "# for n in range(100):\n",
        "#     numbers = gen_numbers_from_probability(ys_pred[0])  \n",
        "#     print('{0} : {1}'.format(n, numbers))    \n",
        "#     list_numbers.append(numbers)  \n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "lotto_base_dir=path.join('./gdrive/My Drive/', '')\n",
        "with open(path.join(lotto_base_dir, \"predict.txt\"), \"w\") as f:\n",
        "  print (\"predict.txt\")\n",
        "\n",
        "  for n in range(50):\n",
        "    numbers = gen_numbers_from_probability(ys_pred[0])  \n",
        "    print('{0} : {1}'.format(n, numbers))    \n",
        "    list_numbers.append(numbers)  \n",
        "    line_str=','.join(str(e) for e in numbers)\n",
        "    line_str += '\\n'\n",
        "    print(line_str)\n",
        "    f.write(line_str)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b46e1ab03b0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# setInterval(ClickConnect, 60 * 1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./drive/MyDrive/my_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   raise IOError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m--> 116\u001b[0;31m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: ./drive/MyDrive/my_model.h5/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzXKsUUUmCyg"
      },
      "source": [
        "# **Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcvMpyO_oXCF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzZWF0ns5Xk6"
      },
      "source": [
        "# 마지막 회차까지 학습한 모델로 다음 회차 추론\n",
        "\n",
        " # 등수와 상금을 반환함\n",
        "# 순위에 오르지 못한 경우에는 등수가 0으로 반환함\n",
        "def calc_reward(true_numbers, true_bonus, pred_numbers):\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for ps in pred_numbers:\n",
        "        if ps in true_numbers:\n",
        "            count += 1\n",
        "\n",
        "    if count == 6:\n",
        "        return 0, mean_prize[0]\n",
        "    elif count == 5 and true_bonus in pred_numbers:\n",
        "        return 1, mean_prize[1]\n",
        "    elif count == 5:\n",
        "        return 2, mean_prize[2]\n",
        "    elif count == 4:\n",
        "        return 3, mean_prize[3]\n",
        "    elif count == 3:\n",
        "        return 4, mean_prize[4]\n",
        "\n",
        "    return 5, 0\n",
        "\n",
        "def gen_numbers_from_probability(nums_prob):\n",
        "\n",
        "    ball_box = []\n",
        "\n",
        "    for n in range(45):\n",
        "        ball_count = int(nums_prob[n] * 100 + 1)\n",
        "        ball = np.full((ball_count), n+1) #1부터 시작\n",
        "        ball_box += list(ball)\n",
        "\n",
        "    selected_balls = []\n",
        "\n",
        "    while True:\n",
        "        \n",
        "        if len(selected_balls) == 6:\n",
        "            break\n",
        "        \n",
        "        ball_index = np.random.randint(len(ball_box), size=1)[0]\n",
        "        ball = ball_box[ball_index]\n",
        "\n",
        "        if ball not in selected_balls:\n",
        "            selected_balls.append(ball)\n",
        "\n",
        "   \n",
        "    selected_balls.sort()\n",
        "\n",
        "    return selected_balls\n",
        "\n",
        "print('receive numbers')\n",
        "\n",
        "xs = x_samples[-1].reshape(1, 1, 45)\n",
        "\n",
        "ys_pred = model.predict_on_batch(xs)\n",
        "\n",
        "list_numbers = []\n",
        "\n",
        "# 50 개 뽑기\n",
        "# for n in range(100):\n",
        "#     numbers = gen_numbers_from_probability(ys_pred[0])  \n",
        "#     print('{0} : {1}'.format(n, numbers))    \n",
        "#     list_numbers.append(numbers)  \n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "lotto_base_dir=path.join('./gdrive/My Drive/', '')\n",
        "with open(path.join(lotto_base_dir, \"predict.txt\"), \"w\") as f:\n",
        "  print (\"predict.txt\")\n",
        "\n",
        "  for n in range(50):\n",
        "    numbers = gen_numbers_from_probability(ys_pred[0])  \n",
        "    print('{0} : {1}'.format(n, numbers))    \n",
        "    list_numbers.append(numbers)  \n",
        "    line_str=','.join(str(e) for e in numbers)\n",
        "    line_str += '\\n'\n",
        "    print(line_str)\n",
        "    f.write(line_str)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOjlv9p90YKR"
      },
      "source": [
        "# **Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzmxpXaV0dCc"
      },
      "source": [
        "model.save('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvzmqDDf17WD"
      },
      "source": [
        "# **Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqdRq1Rn2CKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a5cbfd-918e-4ed9-ef0c-4390a006fd69"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from os import path\n",
        "from google.colab import drive\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "!pip install tensorflow-gpu==2.0.0-rc1\n",
        "\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "\n",
        "new_model = tf.keras.models.load_model('./gdrive/MyDrive/my_model.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-rc1 in /usr/local/lib/python3.7/dist-packages (2.0.0rc1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.34.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.12.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.2)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a20190807,>=1.15.0a20190806 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0a20190806)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.36.2)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.14.0.dev2019080601)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.4.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.3.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-rc1) (56.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (4.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.7.4.3)\n",
            "Mounted at /content/gdrive\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (1, 128)                  89088     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (1, 45)                   5805      \n",
            "=================================================================\n",
            "Total params: 94,893\n",
            "Trainable params: 94,893\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LZbvqHB5E3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc18634-71a0-4a2b-aff2-01fbdf9930f3"
      },
      "source": [
        "!cp /content/my_model.h5 /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: failed to access '/content/drive/My Drive/': Transport endpoint is not connected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBxRkkEHVwU1"
      },
      "source": [
        "# FTP 전송"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1v3JlaOWKAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "762e78ea-c5c2-4706-ef40-dc8a62b3e09b"
      },
      "source": [
        "from ftplib import FTP\n",
        "\n",
        "ftp = FTP('112.175.184.78')\n",
        "ftp.login('dalasjoe', 'Dalasjoe75!')\n",
        "\n",
        "# ftp.cwd('html') # \"test\"디렉터리로 이동\n",
        "# ftp.retrlines('LIST') # 디렉터리의 내용을 목록화\n",
        "# #ftp.retrbinary('RETR README', open('README', 'wb').write) # README 파일 저장\n",
        "# ftp.quit()\n",
        "\n",
        "\n",
        "ftp.cwd('html')  # 업로드할 FTP 폴더로 이동\n",
        "myfile = open(path.join(lotto_base_dir, \"predict.txt\"),'rb')  # 로컬 파일 열기\n",
        "ftp.storbinary('STOR ' + 'predict.txt', myfile )  # 파일을 FTP로 업로드\n",
        "myfile.close()  # 파일 닫기\n",
        "\n",
        "print (\"File Saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVn3rfIyW7OG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSlY9i6yW511"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}